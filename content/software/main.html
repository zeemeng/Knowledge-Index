<ki-section id="software" name="Software">
  <ki-topic id="agile-methodology" name="Agile Software Development Methodology">
    <ki-reflist>
      <ki-ref link="https://docs.google.com/document/d/1sQQyoVwEkBVpEITpOR_crm8ONtUr0Bel5wmLjzQQNJw/edit">About Agile development process.</ki-ref>
      <ki-ref link="https://www.atlassian.com/git/tutorials/comparing-workflows/gitflow-workflow">About Gitflow Workflow</ki-ref>
    </ki-reflist>
  </ki-topic>
  <ki-topic id="gui" name="Graphical User Interface (GUI)">
    <ki-topic id="notes-gui-vid1" name="Notes on Video **GUI: Under the Hood - Computerphile**">
      <ki-reflist>
        <ki-ref link="https://www.youtube.com/watch?v=ptcHHXp1PEU">About what is and makes a GUI.</ki-ref>
      </ki-reflist>
      <ul style="margin-top: 2.5em">
        <li>GUI programs tend to be very similar --&gt; popular usage of frameworks and libraries (esp. object oriented)</li>
        <li>Structure of program based on user triggered events</li>
        <li>At center of program should be a “event loop”</li>
        <li>(From OS) UI toolkit generates events for programs</li>
        <li>For Windows: .NET Framework, MFC</li>
        <li>
          When switching between foreground windows, windows may need to be redrawn. The OS may automatically handle the operation of redrawing the
          windows or it may send a message to the GUI program instructing it to redraw parts of or the entire windows.
        </li>
        <li>Modern OSes may draw all the open windows separately in memory and piece copies of them together to produce a screen output.</li>
      </ul>
    </ki-topic>
    <ki-topic id="notes-gui-vid2" name="Notes on Video **Cross Platform Graphical User Interfaces in C++**">
      <ki-reflist>
        <ki-ref link="https://www.youtube.com/watch?v=FOIbK4bJKS8">
          Excellent tutorial on making GUIs using C++ by
          <em>javidx9</em>
          .
        </ki-ref>
      </ki-reflist>
      <ul style="margin-top: 2.5em">
        <li>Instructions dealing w. wxWidgets API for C++</li>
        <li>
          Examples of available GUI production tools on Windows:
          <ul>
            <li>Windows API (old)</li>
            <li>Microsoft Foundation Classes (old)</li>
            <li>Universal Windows Platform</li>
            <li>C# (programming language w. particular framework called Win Forms)</li>
          </ul>
        </li>
        <li>
          Examples of available GUI production tools on Linux:
          <ul>
            <li>GTK</li>
            <li>Many others</li>
          </ul>
        </li>
        <li>
          Examples of available cross-platform GUI production tools:
          <ul>
            <li>Java (similar feels across platforms since apps run inside a virtual machine)</li>
            <li>
              Qt
              <ul>
                <li>See sub-point of wxWidgets below.</li>
              </ul>
            </li>
            <li>
              WxWidgets
              <ul>
                <li>
                  Both Qt and wxWidgets will use native components of various platforms so that apps written using these tools have a natural fell and
                  look when compiled and run on various platforms such as Windows, Linux, etc.
                </li>
              </ul>
            </li>
          </ul>
        </li>
        <li>To understand GUI programs, they may be broken down and analyzed as 2 different components: structure &amp; events</li>
        <li>
          Structure: defines what the GUI looks like (e.g. a number of nested windows/boxes). These windows are often called forms, frames and
          dialogues as well. The nested nature of these forms means that they may be represented using a tree structure and have certain parent-child
          relationships.
        </li>
        <li>
          Events: represent things that have happened in time. E.g., when a user clicks on a button of a GUI program, a series of events have occurred
          and may be registered. One of these events (e.g. ‘on button clicked’) may be of particular significance for the operation of the program
          such that when it is registered a function of the program is called. However, other events also occurs when user performs such an action
          such as ‘on mouse entry’, on mouse button down, on mouse button up, on mouse leave, etc. It is the job of a good GUI framework to aggregate
          multiple event into a more general one or discard some of the less meaningful events and present the programmer or the program only events
          that has utility. When developing GUIs, after the structure has been established, the programmer shall populate some code with some ‘event
          handlers’ related to functionalities that he wants to implement.
        </li>
        <li>
          This is a contrast to the traditional scheme of programming since we are providing nuggets of code that might be invoked at any point in
          time.
        </li>
        <li>
          Usage documentation for wxWidgets can be found at
          <em>docs.wxwidgets.org</em>
          (e.g. class list)
        </li>
      </ul>
    </ki-topic>
  </ki-topic>
  <ki-topic id="wxwidgets" name="wxWidgets GUI Framework">
    <ki-topic id="wxwidgets-build-install" name="Building and Installing Framework From Source">
      <ki-topic id="wxwidgets-get-source" name="Obtaining the Source Code">
        <ki-reflist>
          <ki-ref link="https://www.wxwidgets.org/">Official releases from wxWidgets framework website.</ki-ref>
          <ki-ref link="https://github.com/wxWidgets/wxWidgets">
            Absolute latest development version
            <strong>with patches</strong>
            and features.
          </ki-ref>
          <ki-ref link="https://github.com/wxWidgets/wxWidgets/blob/master/README-GIT.md">
            Special note about cloning the source code using Git and getting
            <em>submodules</em>
            (i.e. 3rd party libraries code).
          </ki-ref>
        </ki-reflist>
      </ki-topic>
      <ki-topic id="wxwidgets-build-install-windows" name="Build and Install on Windows">
        <ki-reflist>
          <ki-ref link="https://www.youtube.com/watch?v=FOIbK4bJKS8">
            <strong>javidx9's</strong>
            tutorial.
          </ki-ref>
        </ki-reflist>
      </ki-topic>
      <ki-topic id="wxwidgets-build-install-linux" name="Build and Install on Linux">
        <ki-reflist>
          <ki-ref link="https://wiki.wxwidgets.org/Compiling_and_getting_started">About building and installing wxWidgets on Linux.</ki-ref>
          <ki-ref link="https://docs.wxwidgets.org/trunk/plat_gtk_install.html">About building and installing wxWidgets on Linux.</ki-ref>
        </ki-reflist>
      </ki-topic>
      <ki-topic id="wxwidgets-test-samples" name="Testing Sample Programs">
        <ki-reflist>
          <ki-ref link="https://docs.wxwidgets.org/trunk/page_samples.html">About wxWidgets test samples.</ki-ref>
        </ki-reflist>
      </ki-topic>
      <ki-topic id="wxwidgets-eclipse-ide" name="(Supplement) - Integration With Eclipse IDE">
        <ki-reflist>
          <ki-ref link="https://wiki.wxwidgets.org/Eclipse%2C_CDT_%26_MingW_%26_MSYS_Setup_Guide">
            About wxWidgets integration with Eclipse IDE.
          </ki-ref>
          <ki-ref link="https://wiki.wxwidgets.org/Eclipse">About wxWidgets integration with Eclipse IDE.</ki-ref>
          <ki-ref link="http://max.berger.name.s3-website-us-east-1.amazonaws.com/howto/wxWidgets/eclipse/">
            Some personal blog with tips for setting up wxWidgets.
          </ki-ref>
        </ki-reflist>
      </ki-topic>
    </ki-topic>
    <ki-topic id="wxwidgets-build-env-gcc" name="Application Build Environment on Linux With GCC">
      <ki-reflist>
        <ki-ref link="https://wiki.wxwidgets.org/Eclipse%2C_CDT_%26_MingW_%26_MSYS_Setup_Guide">
          About building wxWidgets applications using GCC.
        </ki-ref>
      </ki-reflist>
      <p>
        When building GUI applications with GCC, one may use the
        <ki-icode>wx-config</ki-icode>
        command-line utility to produce GCC commands. The
        <ki-icode>wx-config</ki-icode>
        utility provides various functionalities and information relating to the current installation of WxWidgets. Notably, when supplied with the
        <ki-icode>--cxxflags</ki-icode>
        option as follows,
        <ki-icode>wx-config --cxxflags</ki-icode>
        , the utility returns a string containing a set of include-related options for GCC (and presumably other compatible build tools). For example,
        the return value might be:
        <ki-icode>
          -I/usr/local/lib/wx/include/gtk3-unicode-3.1 -I/usr/local/include/wx-3.1 -D_FILE_OFFSET_BITS=64 -DWXUSINGDLL -D__WXGTK__ -pthread
        </ki-icode>
        . Also, when supplied with the
        <ki-icode>--libs</ki-icode>
        option as follows,
        <ki-icode>wx-config --libs</ki-icode>
        , the utility returns a string containing a set of library-related options for GCC (and presumably other compatible build tools). For example,
        the return value might be:
        <ki-icode>
          -L/usr/local/lib -pthread -lwx_gtk3u_xrc-3.1 -lwx_gtk3u_html-3.1 -lwx_gtk3u_qa-3.1 -lwx_gtk3u_core-3.1 -lwx_baseu_xml-3.1 -lwx_baseu_net-3.1
          -lwx_baseu-3.1
        </ki-icode>
        .
      </p>
      <p>
        As such, when producing GCC commands, instead of manually typing the correct set of include-related and library-related GCC options, one may
        substitute them with
        <ki-icode>wx-config</ki-icode>
        plus the relevant flags, with the substituting utility command surrounded by a single back-ticks preceding it and another following it. For
        example, a GCC build command might look like this:
        <ki-icode>g++ file1.cpp file2.cpp `wx-config --cxxflags --libs` -oExec</ki-icode>
        . It is important that the back-ticks in the command are not confounded with single-quotes as they have different usages and functionalities.
        It is also important that on the command,
        <ki-icode>`wx-config --libs`</ki-icode>
        appears after all source files which make use of xxWidgets libraries for if not, the linker will be unable to locate the library files causing
        a fatal error due to unresolved references.
      </p>
    </ki-topic>
    <ki-topic id="wxwidgets-sizers" name="Sizers &amp; Layout Management">
      <ki-reflist>
        <ki-ref link="http://zetcode.com/gui/wxwidgets/layoutmanagement/"></ki-ref>
      </ki-reflist>
    </ki-topic>
    <ki-topic id="wxwidgets-events" name="Events &amp; Event Handling">
      <ki-reflist>
        <ki-ref link="https://docs.wxwidgets.org/trunk/classwx_evt_handler.html"></ki-ref>
        <ki-ref link="https://docs.wxwidgets.org/trunk/overview_events.html"></ki-ref>
        <ki-ref link="https://wxwidgets.blogspot.com/2007/01/in-praise-of-connect.html"></ki-ref>
        <ki-ref link="http://zetcode.com/gui/wxwidgets/events/"></ki-ref>
        <ki-ref link="https://docs.wxwidgets.org/trunk/group__group__class__events.html"></ki-ref>
        <ki-ref link="https://docs.wxwidgets.org/trunk/group__group__funcmacro__events.html"></ki-ref>
      </ki-reflist>
      <p>The event handling system of wxWidgets is primarily directed by the interaction of several core elements from the API which are:</p>
      <ul>
        <li>Event type</li>
        <li>Event class</li>
        <li>Event handler function</li>
        <li>Event-generating object</li>
        <li>Event binding</li>
      </ul>
      <p>A general description of each of these, including their functions within the event handling system is presented below.</p>
      <ul>
        <li>
          Event type: This is an enum integer element which uniquely identifies the type of a given event. Each event type is associated with a single
          event class. Although, more than one event type may be associated with the same event class.
        </li>
        <li>
          Event class: An instance of an event class represents an actual event which occurred and needs to be handled by the wxWidgets framework.
          Such an object contains information relating to the event including the ID of and a pointer to the object which generated the event, and may
          include the position of the mouse, a
          <ki-icode>wxString</ki-icode>
          , and more. Several different event classes exist which may have different properties and carry different information. Examples of event
          class are
          <ki-icode>wxMouseEvent</ki-icode>
          ,
          <ki-icode>wxClipboardTextEvent</ki-icode>
          ,
          <ki-icode>wxKeyEvent</ki-icode>
          ,
          <ki-icode>wxCommandEvent</ki-icode>
          , etc. A ubiquitous and commonly used event for application development is
          <ki-icode>wxCommandEvent</ki-icode>
          . It is a synthesized, higher level event produced by wxWidgets when one of its controls has been interacted with or activated by the user
          such as when a button has been pressed by a mouse left click followed by a mouse release. Unlike other event classes, an instance of the
          <ki-icode>wxCommandEvent</ki-icode>
          class is propagate from the event-generating or the current object to its parent object if the current object does not handle the event.
          Whereas by default, instances of all other event classes are not propagated.
        </li>
        <li>
          Event handler function: This is a function which would get called by the wxWidgets event handling system when a particular event object as
          described above is caught by an object derived from
          <ki-icode>wxEvtHandler</ki-icode>
          class (which is most classes of the wxWidgets framework). Once an event handler function is dispatched, the associated event is considered
          to be “handled” and no more action with respect to that particular event occurs, unless the event handler function calls
          <ki-icode>wxEvent::Skip()</ki-icode>
          which signals that the event shall NOT be considered to be “handled”. Traditionally, all event handler functions needs to be defined within
          classes derived from
          <ki-icode>wxEvtHandler</ki-icode>
          , but if dynamic event binding is employed using
          <ki-icode>wxEvtHandler::Bind&lt;&gt;()</ki-icode>
          , no such restriction applies and any arbitrary function may be used as an event handler function.
        </li>
        <li>
          Event-generating object: This represent an object from where, a particular event has been generated. This might be a button, a frame, a text
          box, etc. The same object may also catch and handle the event.
        </li>
        <li>
          Event binding: Event binding is the act of associating an event handler function to events meeting certain criteria. The criteria may
          include the event type, the ID of the event-generating object and which object catches the event. There are two modes of event binding in
          wxWidgets, static binding and dynamic binding. The former entails that event bindings are performed at compile time, whereas the latter
          means that bindings occur during application runtime. Traditionally, event bindings are performed statically, implemented through a
          macro-based approach called “event tables”. An event table is essentially a centralized list of all bindings relating to events that shall
          be handled by a particular class of objects. Such a class is required to be derived from
          <ki-icode>wxEvtHandler</ki-icode>
          class. To be able to use an event table, the declaration of a class which uses such table needs to include the following macro line:
          <ki-icode>wxDECLARE_EVENT_TABLE();</ki-icode>
          . Then in the implementation file (.cpp file), in the global scope, should be the actual event table, which may look like this:
          <ki-code path="/content/software/wxwidgets-events.eg1.cpp"></ki-code>
          <ki-cite ref="@2">Ref. 2</ki-cite>
          <div style="margin-top: 1.5em">
            An event table shall begin with the following line:
            <ki-icode>wxBEGIN_EVENT_TABLE()</ki-icode>
            , which takes two parameters. The first of which is the class that uses the event table, and the second is the immediate base class from
            which that in the first parameter is derived. An event table shall end with the line:
            <ki-icode>wxEND_EVENT_TABLE()</ki-icode>
            . In between the starting and ending lines are the entries which defines the actual bindings. An entry takes the form of a unique macro
            for every event type (though custom event types may not and need not implement event table macros). All such macros take as parameter
            between parentheses the event handler function to be associated with this entry and may take additional parameters such as the ID of the
            event-generating object. All the event handler functions that are used in event table entries need to be defined in the class which uses
            the event table (as specified by the first parameter of
            <ki-icode>wxBEGIN_EVENT_TABLE()</ki-icode>
            ).
          </div>
          <div style="margin-top: 1.5em">
            Event bindings may also be perform dynamically during application runtime. This possibility came to wxWidgets later on historically, but
            it is more powerful and flexible than the traditional mode of static binding. Dynamic binding may be achieved in two ways, both of which
            involves using member functions of the
            <ki-icode>wxEvtHandler</ki-icode>
            class. The first of these uses the
            <ki-icode>wxEvtHandler::Connect()</ki-icode>
            function. The other uses the
            <ki-icode>wxEvtHandler::Bind&lt;&gt;()</ki-icode>
            function, which has effectively superseded
            <span>Connect()</span>
            . Implementing either of these provide advantages over the traditional way of static binding through macro tables. In fact, handler
            functions could thus be bound at any moment which means that objects can be initialized and validated beforehand so that binding would not
            take place if the object wasn’t initialized properly, and by the same token this saves initialization and validation code from being
            included in the handler functions themselves. Handler functions can also be unbound and rebound during execution. While this feature may
            be emulated in the event table approach by including internal flags in the handler function code, it would result in more code and
            clutter. Most importantly, dynamic binding also allows more freedom in the type function that may be used for event handling, more on that
            later. In order to implement dynamic binding through either of the two ways, no macro usage is needed. Simply call either
            <ki-icode>Connect()</ki-icode>
            or
            <ki-icode>Bind()</ki-icode>
            on the object which is to handle some given event (for function prototypes see Ref.1). These calls may be located in the body of any class
            that gets instantiated or of any function that gets executed.
            <ki-icode>Connect()</ki-icode>
            accepts as event handler function any member function of a
            <ki-icode>wxEvtHandler</ki-icode>
            class including classes other than that of the object which catches and handles the event (something that was not possible using event
            tables). Whereas
            <ki-icode>Bind()</ki-icode>
            provides even more flexibility by allowing any arbitrary function or functor to be used as event handler function, which is one of the
            reasons why
            <ki-icode>Bind()</ki-icode>
            should be preferred over
            <ki-icode>Connect()</ki-icode>
            . Due to their prototypes,
            <ki-icode>Bind()</ki-icode>
            also seems to require less typing in its argument fields in many cases.
          </div>
        </li>
      </ul>
    </ki-topic>
    <ki-topic id="wxwidgets-object-deletion" name="wxWidgets Object Deletion">
      <ki-reflist>
        <ki-ref link="https://wiki.wxwidgets.org/Avoiding_Memory_Leaks"></ki-ref>
        <ki-ref link="https://docs.wxwidgets.org/trunk/overview_windowdeletion.html"></ki-ref>
      </ki-reflist>
    </ki-topic>
    <ki-topic id="wxwidgets-images" name="Image Usage and Handling">
      <ki-reflist>
        <ki-ref link="https://en.wikipedia.org/wiki/Bitmap"></ki-ref>
        <ki-ref link="https://en.wikipedia.org/wiki/Vector_graphics"></ki-ref>
        <ki-ref link="https://en.wikipedia.org/wiki/Raster_graphics"></ki-ref>
        <ki-ref link="https://docs.wxwidgets.org/3.0/classwx_bitmap.html"></ki-ref>
        <ki-ref link="https://docs.wxwidgets.org/trunk/classwx_image.html"></ki-ref>
        <ki-ref link="https://docs.wxwidgets.org/trunk/classwx_static_bitmap.html"></ki-ref>
        <ki-ref link="https://wiki.wxwidgets.org/Embedding_PNG_Images"></ki-ref>
        <ki-ref link="https://docs.wxwidgets.org/3.0/overview_bitmap.html"></ki-ref>
        <ki-ref link="https://docs.wxwidgets.org/3.0/gdicmn_8h.html"></ki-ref>
        <ki-ref link="https://docs.wxwidgets.org/3.0/classwx_bitmap_handler.html"></ki-ref>
        <ki-ref link="https://wiki.wxwidgets.org/An_image_panel"></ki-ref>
      </ki-reflist>
      <p>
        wxWidgets handles images through two of its classes,
        <ki-icode>wxImage</ki-icode>
        and
        <ki-icode>wxBitmap</ki-icode>
        .
        <ki-icode>wxImage</ki-icode>
        loads images as simply a buffer of RGB bytes with an optional buffer for the alpha channel (for transparency). The format of the data is the
        same across platforms making it portable.
        <ki-icode>wxImage</ki-icode>
        also “includes generic code for scaling, resizing, clipping, and other manipulations of the image data”. However, “a wxImage cannot
        (currently) be be drawn directly to” the screen or a device context (
        <ki-icode>wxDC</ki-icode>
        ) since the data it contains needs to be converted to a platform specific native image format for such purposes. On the other hand,
        <ki-icode>wxBitmap</ki-icode>
        does load and store images in “the native format that is quickest/easiest to draw to a DC or to be the target of the drawing operations
        performed on a
        <ki-icode>wxMemoryDC</ki-icode>
        .” Although, it does not have the image manipulation capabilities that
        <ki-icode>wxImage</ki-icode>
        has. Conversion between an
        <ki-icode>wxImage</ki-icode>
        object and a
        <ki-icode>wxBitmap</ki-icode>
        object can be easily carried out in either direction. A wxImage object can load and save images to and from most of the popular formats for as
        long as a suitable image handler (e.g.
        <ki-icode>wxPNGHandler</ki-icode>
        ,
        <ki-icode>wxJPEGHandler</ki-icode>
        ) exists. To use the features provided by a given image handler, the handler needs to be added to the application manually by calling
        <ki-icode>wxImage::AddHandler(wxImageHandler* whatever)</ki-icode>
        or
        <ki-icode>wxInitAllImageHandlers()</ki-icode>
        , which perform what their name suggests.
        <ki-icode>wxImage</ki-icode>
        can also load images from a variety of sources such as files, memory locations and platform specific resource locations. Concerning
        <ki-icode>wxBitmap</ki-icode>
        , it can also load and save images to and from a number of formats depending on the platform and wxWidgets configuration. However, “all
        available
        <ki-icode>wxBitmapHandlers</ki-icode>
        for a given wxWidgets port are automatically loaded at startup so you won't need to use
        <ki-icode>wxBitmap::AddHandler()</ki-icode>
        ”.
        <ki-icode>wxBitmap</ki-icode>
        can also load images from a variety of sources such as files, memory locations and platform specific resource locations.
      </p>
      <div>
        Concerning the usage of a loaded image in a wxWidgets application, 4 apparent use cases can be noted. These include the following:
        <ul>
          <li>Image set as background</li>
          <li>Image set as label and icon</li>
          <li>
            Image used as a manipulable static bitmap control (
            <ki-icode>wxStaticBitmap</ki-icode>
            or
            <ki-icode>wxGenericStaticBitmap</ki-icode>
            )
          </li>
          <li>Image directly drawn to a device context</li>
        </ul>
        Instructions on how to implement these use cases in applications should be well documented in official online documentation.
      </div>
    </ki-topic>
    <ki-topic id="wxwidgets-fonts" name="Fonts">
      <ki-reflist>
        <ki-ref link="https://docs.wxwidgets.org/trunk/overview_font.html"></ki-ref>
        <ki-ref link="https://wiki.wxwidgets.org/WxFont"></ki-ref>
        <ki-ref link="https://docs.wxwidgets.org/trunk/classwx_font.html"></ki-ref>
        <ki-ref link="https://docs.wxwidgets.org/trunk/classwx_font_info.html"></ki-ref>
        <ki-ref link="https://docs.wxwidgets.org/trunk/classwx_window.html#a0dcc6f6f7bda203a868ff10c413289fa"></ki-ref>
        <ki-ref link="https://docs.wxwidgets.org/trunk/interface_2wx_2font_8h.html"></ki-ref>
      </ki-reflist>
    </ki-topic>
  </ki-topic>
  <ki-topic id="licenses" name="Licenses">
    <ki-reflist>
      <ki-ref link="https://en.wikipedia.org/wiki/Software_license">General introduction.</ki-ref>
      <ki-ref link="https://choosealicense.com/">Simple guide on choosing a FOSS license.</ki-ref>
      <ki-ref link="https://choosealicense.com/no-permission/">Implications of publishing works without license.</ki-ref>
      <ki-ref link="https://choosealicense.com/licenses/">Comparison of prominent open source licenses.</ki-ref>
      <ki-ref link="http://www.lurklurk.org/licenses.html">Comparison of prominent open source licenses.</ki-ref>
      <ki-ref link="https://choosealicense.com/appendix/">Table of most open source licenses and their characteristics.</ki-ref>
      <ki-ref link="https://choosealicense.com/non-software/">Short commentary about non-software licenses.</ki-ref>
      <ki-ref link="https://en.wikipedia.org/wiki/GNU_General_Public_License">About GNU General Public License (GPL).</ki-ref>
      <div>Supplement:</div>
      <ki-ref link="https://www.10duke.com/software-licensing-models/">About proprietary software licenses.</ki-ref>
    </ki-reflist>
  </ki-topic>
  <ki-topic id="programming-languages" name="Types of Programming Languages by Level of Abstraction">
    <ki-topic id="high-level-langs" name="High-Level Languages">
      <p>
        The most abstract category of programming languages in contemporary times are so called “high-level languages” (HLL). These include languages
        such as C++, C#, Java, Python, etc. These have the characteristic of having a form and syntax that is in some respect close to those of
        natural languages like English or French. Due to these traits, they are relatively easier for humans to interact with and to use for code
        production compared to other categories of programming languages and thus they are also the most popular type of language that computer
        programmers use for writing code.
      </p>
    </ki-topic>
    <ki-topic id="assembly" name="Assembly Languages">
      <ki-reflist>
        <ki-ref link="https://www.youtube.com/watch?v=zltgXvg6r3k&amp;list=PL8dPuuaLjXtNlUrzyH5r6jN9ulIgZBpdo"></ki-ref>
        <ki-ref link="https://www.youtube.com/watch?v=RU1u-js7db8&amp;list=PL8dPuuaLjXtNlUrzyH5r6jN9ulIgZBpdo"></ki-ref>
        <ki-ref link="https://en.wikipedia.org/wiki/Assembly_language#Assembly_language_syntax"></ki-ref>
      </ki-reflist>
      <p>
        Assembly languages are a lower-level category of programming language, that are closely related to machines languages and binary code. In
        fact, statements in assembly languages have a 1-to-1 correspondence relationship with individual CPU instructions. Where each binary
        CPU/machine instruction usually starts with an opcode represented by a group of bits which may be followed by operands represented by
        subsequent groups of bits, unless the instruction is one which does not require any operand such as a “halt” instruction, in assembly language
        the binary opcode is replaced by an easier to recognize “mnemonic” and the operands are replaced by decimals or convenient labels. These
        characteristics makes writing computer programs more tractable than producing them in pure binary machine code. An assembler which is a tool
        used to convert assembly code to machine code may provide additional benefits to the programmer such as automatically calculating and
        determining jump addresses and offset memory locations. It is noteworthy to state that due to assembly languages’ close correspondence to
        machine languages which vary depending on the instruction set of the targeted CPU, there are in theory as many assembly languages as there are
        different CPU instruction sets.
      </p>
    </ki-topic>
    <ki-topic id="machine-langs" name="Machine Language (Binary)">
      <ki-reflist>
        <ki-ref link="https://www.youtube.com/watch?v=zltgXvg6r3k&amp;list=PL8dPuuaLjXtNlUrzyH5r6jN9ulIgZBpdo"></ki-ref>
        <ki-ref link="https://www.youtube.com/watch?v=RU1u-js7db8&amp;list=PL8dPuuaLjXtNlUrzyH5r6jN9ulIgZBpdo"></ki-ref>
        <ki-ref link="https://en.wikipedia.org/wiki/Opcode"></ki-ref>
      </ki-reflist>
      <p>
        Concerning conventional modern digital computers, machine languages are lexically, entirely composed of binary digits that have been termed as
        “bits”. Each instruction may be composed of a fixed number of bits or of variable numbers of bits depending on the instruction set
        architecture of the CPU for which the language is intended. The first part of these instructions is usually the “opcode” (short of operation
        code). It consists of a group of bits at the beginning of and within the full set of bits that forms the complete instruction. This opcode
        determines the nature of the operation to be executed and may be followed by a number of associated “operands” formed by subsequent groups of
        bits, or in some cases an opcode may appear without the need of any operand, such as for a “halt” instruction. As previously mentioned,
        machine languages depend and vary with CPU instruction set architectures (ISAs). Different ISA would introduce different available operations
        on a given machine and therefore different instruction types for the associated machine language. Programs produced in machine language may be
        stored solely in a machine’s memory or on a persistent storage medium or on both. Regardless of the storage medium, instructions within
        programs written in machine code are stored one immediately after the other which would give the visual appearance of a long string of bits
        that would be hard to comprehend for a human.
      </p>
    </ki-topic>
    <ki-topic id="intermediate-langs" name="Intermediate Representations &amp; Intermediate Languages">
      <ki-reflist>
        <ki-ref link="https://en.wikipedia.org/wiki/Intermediate_representation"></ki-ref>
        <ki-ref link="https://www.cs.princeton.edu/courses/archive/spr03/cs320/notes/IR-trans1.pdf"></ki-ref>
        <ki-ref link="https://en.wikipedia.org/wiki/Bytecode"></ki-ref>
        <ki-ref link="https://en.wikipedia.org/wiki/Virtual_machine"></ki-ref>
        <ki-ref link="https://opensource.com/article/18/4/introduction-python-bytecode"></ki-ref>
        <ki-ref link="http://www.techdarting.com/2014/04/python-compiled-or-interpreted-language.html"></ki-ref>
        <ki-ref link="https://www.tutorialspoint.com/compiler_design/compiler_design_intermediate_code_generations.htm"></ki-ref>
        <ki-ref link="https://en.wikipedia.org/wiki/GNU_Compiler_Collection#GENERIC_and_GIMPLE"></ki-ref>
      </ki-reflist>
      <p>
        Intermediate representations (IR) are code or data structures that are subject to further processing by a compiler, interpreter or other such
        tools before being transformed into code that is directly executable by a CPU. Where some form of IR consists of transitory code in a
        translation process, the specifications which describes such code is termed an intermediate language.
      </p>
      <p>
        Examples of IR may include graph structures produced and used during the operations of different compilers’ front-end stage, such as concrete
        syntax trees (also known as parse trees) and abstract syntax trees (AST). These types of IRs have low portability potential between different
        toolsets, and low retargetability potential between modules of the same toolset since their implementations are affect by source language
        specifications and toolset design. Although they are indeed very useful constructs during early phases of the program translation process,
        they are commonly transformed into more generic forms of IRs such as forms of three-address code (e.g. GIMPLE for GCC) for use during later
        phases. A particular type of intermediate code with good portability is the bytecode.
      </p>
      <p>
        A bytecode is a form of instruction set designed to be interpreted efficiently by a virtual machine (VM). The term bytecode is named as such
        due to those instruction sets that have one-byte opcodes, though they may also be know as portable code or p-code. Bytecode is quite similar
        to regular machine code in many aspects, although it is not intended to be fed to a physical machine, but rather a virtual one. As such,
        bytecode files are stored in binary form and can be disassembled for programmer inspection using the right utility. A main motivation for
        using bytecode is to increase program portability. Since the execution environment of the bytecode is within the VM, every platform or
        physical machine which have an implementation of the VM have the ability to run programs stored in its corresponding bytecode form. A given
        bytecode and its VM execution environment are also not bound to any particular source programming language, although they may be more
        popularly used for programs written in a particular source language. For example, Java bytecode is primarily used for programs written in Java
        source code, which following translation may be run within Java Virtual Machines (JVM). However, the Jython interpreter also translates Python
        source programs to Java bytecode for execution within JVM. An interesting side note given the present definition of intermediate
        representation is that hypothetically, it could be possible to construct a physical machine with an architecture capable of executing a given
        type of bytecode instructions directly without further translation, rendering the “intermediate” nature of that bytecode less so.
      </p>
      <p>
        Although the use of generic and/or portable types of intermediate representations in the build process of compiled language programs is not
        necessary since following the semantic analysis phase, assembly or machine code can be generated directly, numerous reasons and advantages led
        to the widespread practice of converting the program into a generic and/or portable IR form. Some of these reasons include increasing code
        portability and sharing machine-independent code optimizations between various target platforms performed on such IRs . Another main advantage
        of using generic/portable IR is the increase in compiler program modularity which greatly eases the design and production of compilers. This
        can be demonstrated by considering the following situation. In order to build compilers for
        <strong>n</strong>
        source languages and
        <strong>m</strong>
        target machines, without the use of generic/potable IR, one would need to create a distinct compiler for each source language-target machine
        pair, necessitating a total of
        <strong>n * m</strong>
        compilers. However, by making use of generic/potable IR, one would only need to implement
        <strong>n</strong>
        front-ends capable of emitting such IR, and
        <strong>m</strong>
        back-ends capable of taking such IR as input. By combining one of those front-ends to one of those back-ends, various compilers supporting
        each of the specified source languages and target machines may be produced.
      </p>
    </ki-topic>
  </ki-topic>
  <ki-topic id="types-of-program-codes" name="Types of Program Codes">
    <ki-topic id="source-code" name="Source Code">
      <p>
        Strictly stated, source code is program code which serves as input to a translation process, hence the term “source”. In accordance with such
        a statement, it may include code written in a variety of languages of different levels of abstraction. However, the term commonly refers to
        code written in high-level languages, since these provide the most convenient interaction and usage for human programmers, thus these are
        generally used in the production of source codes.
      </p>
    </ki-topic>
    <ki-topic id="object-code" name="Object Code">
      <p>
        Strictly stated, object code is program code which is emitted as the result of a translation process, where the term “object” points to the
        nature of such code being the object of that process. In general, with respect to the compilation process, it refers to code written in
        machine language that is not yet executable (to be further processed by a linker), although some compilers may emit code in assembly language
        or even in a basic high-level language such as C.
      </p>
    </ki-topic>
    <ki-topic id="executable-code" name="Executable Code">
      <p>Executable code is code which consists of instructions that once loaded are directly executable by a physical machine or a CPU.</p>
    </ki-topic>
    <ki-topic id="libraries" name="Libraries">
      <p>
        Libraries are an aggregate collection of program instructions written in machine code where such instructions may be accessed by a linker
        which would provide these instructions and their functionalities to other programs that contain references to them. Libraries can be
        distinguished into 2 types, static and dynamic. When static libraries are used, referenced instructions are copied (by the linker) into the
        code of the program referencing them. When dynamic libraries are used, referenced instructions are not copied, instead the program containing
        references will have “binding(s)” to the library file itself, and during that program’s execution, the code within the library file will be
        executed.
      </p>
    </ki-topic>
  </ki-topic>
  <ki-topic id="abi-binary-formats" name="ABIs and Binary File Formats">
    <ki-topic id="abi" name="Application Binary Interface">
      <ki-reflist>
        <ki-ref link="https://en.wikipedia.org/wiki/Application_binary_interface"></ki-ref>
      </ki-reflist>
      <p>
        An application binary interface (ABI) could be stated as a set of conventions, rules and standards which specifies precisely how various
        machine code modules should interact with each other in a local environment. Aspects that might be covered by an ABI include data structure
        alignment (the way data is arranged and accessed in computer memory), calling convention (how subroutines receive parameters from their caller
        and how they return a result), stack frame organization, memory access behavior, code relocation, name mangling for languages such as C++,
        system call operations and machine/binary code file formats among many others. Some compatibility features could be available for various
        machine code modules designed with support for a common ABI. For example, a program designed for a particular OS supporting a given ABI might
        possibly run without modification on another OS supporting the same ABI.
      </p>
    </ki-topic>
    <ki-topic id="binary-compatibility" name="Binary Code Compatibility">
      <ki-reflist>
        <ki-ref link="https://en.wikipedia.org/wiki/Binary-code_compatibility"></ki-ref>
      </ki-reflist>
      <p>
        Binary code compatibility is a concept that applies in the contexts of cross-platform compatibility and of backward-compatibility. In either
        case, it means that programs and machine code designed and produced for a given target system or platform is also able to be run or used on
        another compatible system or platform without modification. For such compatibility feature to be available, the compatible system/platform,
        hereby stated in contrast to the native system/platform for which some given piece of machine code is intended to run on, needs to have all of
        the features and requirements of the native system necessary to run that piece of code, although the compatible system may potentially have
        extra features and specifications of its own. Concretely binary code compatibility between two systems usually mean that they share a common
        CPU instruction set, a common ABI and possibly some common APIs. In the context of cross-platform compatibility, it means that this feature
        exists between sufficiently distinct systems. An example of this can be noted in FreeBSD and other members of the BSD family having binary
        compatibility with the Linux kernel in usermode. In the context of backward-compatibility, this feature applies between an older and a newer
        generation of a given system, for example between windows XP and windows 7. In cases where no explicit binary code compatibility exists
        between two systems, emulators and intricate “compatibility layers” (e.g. Wine) can be used to run applications native to one system on the
        other.
      </p>
    </ki-topic>
    <ki-topic id="binary-formats" name="Binary File Formats">
      <ki-reflist>
        <ki-ref link="https://en.wikipedia.org/wiki/Comparison_of_executable_file_formats"></ki-ref>
      </ki-reflist>
      <p>
        It specifies the layout and formatting of binary code files to employ on a given computer system. Examples of file types which are subject to
        binary file formats are libraries, object code files, executable code files and etc. It is usually defined as part of an operating system ABI.
        On Microsoft Windows, the Portable Executable format is used. On GNU/Linux, the ELF format is used. On macOS and iOS, the Mach-O format is
        used.
      </p>
    </ki-topic>
  </ki-topic>
  <ki-topic id="program-execution-models" name="Program Execution Models">
    <p>
      A program execution model describes the stages that a computer program goes through, starting from source code representation all the way to
      being executed by a physical machine or CPU, and answers the question, “how can a source program get actuated?”. Most program implementations
      correspond to one of the following three execution models, the first being the build and execute model, the second being the interpreted model
      and the third being a hybrid of the first and the second.
    </p>
    <p>
      Although source code written in a particular high level programming language may be commonly implemented using a specific execution model be it
      interpreted or built and executed (colloquially described as “compiled” type) or otherwise, this trait is not an inherent feature of the
      language itself but simply reflects popular practice. In fact, any high level language may be implemented using any execution model. For
      example, C, a traditionally “compiled/built and executed” language can be interpreted, just as Python, which traditionally uses an interpreted
      or a hybrid approach, can be fully compiled under a “build and execute” model. What defines a programming language is a language specification
      which is a standards documentation stipulating how a language should work and behave, but seldom requiring a particular translation method or
      execution model. Features of a language may however influence implementation choices and make it suitable for a particular execution model, for
      example whether the language is statically typed or dynamically typed.
    </p>
    <ki-topic id="build-and-execute-model" name="Build and Execute Model">
      <ki-reflist>
        <ki-ref link="https://www.tenouk.com/ModuleW.html"></ki-ref>
        <ki-ref link="https://inst.eecs.berkeley.edu/~cs61c/sp10/lec/19/2010SpCS61C-L19-ddg-RunProgII.pdf"></ki-ref>
      </ki-reflist>
      <p>
        The build and execute model may be first broken down into two distinct processes that may be performed at separate times, namely the build
        process and the execution process. During the build process, the source is transformed in a number of steps ultimately into binary machine
        instructions (something that a machine is enable to understand and execute). Following the program’s translation into an executable binary
        form, during the execution process, it is moved from it’s storage location to the computer’s main memory (it may originally be in the main
        memory, upon which this move operation would not be necessary).
        <span style="color: rgb(255, 208, 0)">Then, another loader program feeds the subject program from memory to the CPU for execution.</span>
        Once execution is finished, the subject program is freed from memory. It should be noted that the build process needs to occur only once. Upon
        which, the built binary executable may be stored on a permanent storage medium. In contrast, the execution process may occur multiple times,
        which would be undertaken every time the executable program is called upon as requested by a user.
      </p>
      <ki-topic id="build-process" name="Build Process">
        <ki-reflist>
          <ki-ref link="https://codingfreak.blogspot.com/2008/02/compilation-process-in-gcc.html"></ki-ref>
          <ki-ref link="https://docs.microsoft.com/en-us/cpp/preprocessor/phases-of-translation?view=vs-2019"></ki-ref>
        </ki-reflist>
        <p>
          As the program source file written in a high-level language gets translated into a binary form which would be readily executable by a target
          CPU, it goes through the following stages.
        </p>
        <p>
          It should be noted that the stages described in this section represent logical steps in the translation and construction of a target program
          under the build and execute model. These logical steps may or may not correspond to distinct modules or utilities included in a given
          program translation toolset. In fact, it may be the case that one module or utility performs the tasks of more than one logical step, just
          as the tasks of a single logical step may be accomplished using more than one module or utility. It may even be the case that a particular
          module performs part of the tasks of one logical step as well as part of the tasks of the next.
        </p>
        <ol>
          <li>
            <div>
              <strong>Preprocessing</strong>
              :
            </div>
            <p>
              Comments are removed. Physical lines of code may be joined to form logical lines (line splicing). Preprocessing directives (lines of
              code beginning with the
              <ki-icode>#</ki-icode>
              character) are executed. These include expansion of defined macros, merging of
              <ki-icode>#include</ki-icode>
              files, code exclusion based on conditional compilation, etc. Each file that results from the preprocessing stage is called a
              <em>translation unit</em>
              , which may be store as a distinct output file, but most often in practical is considered a temporary file to be discarded at the end of
              the build as it might be stored on disk or only in memory.
            </p>
          </li>
          <li>
            <div>
              <strong>Compilation</strong>
              :
            </div>
            <ki-reflist>
              <ki-ref link="http://manpages.ubuntu.com/manpages/trusty/man1/arm-linux-androideabi-gcc.1.html"></ki-ref>
              <ki-ref link="https://en.wikibooks.org/wiki/GNU_C_Compiler_Internals/GNU_C_Compiler_Architecture"></ki-ref>
              <ki-ref link="https://clang.llvm.org/docs/DriverInternals.html"></ki-ref>
            </ki-reflist>
            <p>
              The preprocessed code is taken as input. At this stage the objective is to transform the code into a binary form that is suitable for
              linking. The steps in the compilation stage may vary from toolset to toolset as there is no single regimented way of accomplishing the
              goal, although some steps are more essential than others and are therefore implemented in some fashion in all toolsets. In the early
              stage, the input source code is
              <em>parsed</em>
              to produce an internal representation of the program within the compiler (usually in the form of a syntax tree). Then it goes through
              multiple rounds of analysis which modifies this internal representation. The compiler might potentially transform its internal
              representation of the program into different forms of intermediate representation at various point of the compilation process. It might
              also perform optimizations on the code that it produces in order to render such code more efficient. Lastly, the compiler translates the
              intermediate representation of the program into machine instructions for a specific target machine. As previously stated, the objective
              is to produce binary format code that is suitable for the link stage. To that end, the output of the compiler module may vary between
              various program translation toolsets depending on the design and implementation of those tools. For example, some toolsets may have the
              compiler module output machine instructions first in assembly code format. This assembly code would then be passed to another module
              called an assembler which would ultimately translate the assembly code into binary machine code. Toolsets that implement such a design
              include the GNU Compiler Collection (GCC) and the Clang/LLVM toolset. Another design implementation may have the compiler module
              directly generate binary machine instructions without outputting assembly format code and without requiring another assembler module.
              This seems to be the case for the Microsoft C/C++ compiler unless assembly format code is still involved as an internal intermediate
              representation which is doubtfully the case (See §Program Compilation Process; §§Case Study: Microsoft C/C++ Compiler). Yet other design
              implementations may have the compiler module output code not in machine specific instructions but rather as machine independent,
              intermediate and transitory code to be fed as input to other tools or modules. For example, early C++ compilers would emit code in C
              which would subsequently be compiled by a C compiler. The reason for this is that as a more mature language at the time, lots of C
              compilers already existed for a variety of platforms and translating C++ code into C code allowed C++ source programs to be portable to
              all those platforms.
            </p>
          </li>
          <li>
            <div>
              <strong>Assembly</strong>
              (Optional):
            </div>
            <ki-reflist>
              <ki-ref link="https://techdifferences.com/difference-between-compiler-and-assembler.html"></ki-ref>
              <ki-ref link="https://en.wikibooks.org/wiki/X86_Disassembly/Assemblers_and_Compilers"></ki-ref>
              <ki-ref link="https://inst.eecs.berkeley.edu/~cs61c/sp10/lec/18/2010SpCS61C-L18-ddg-RunProgI-6up.pdf"></ki-ref>
            </ki-reflist>
            <p>
              As mentioned in the prior
              <em>compilation</em>
              section, not all toolsets require the use of a separate assembler module. Therefore, this section describes only parts of those toolsets
              that do make use of an assembler (such as GCC and Clang/LLVM). The assembler takes as input the assembly code produced by the compiler
              and translates it into binary machine code that is ready for the link stage. Since assembly instructions usually have a one to one
              correspondence relationship with binary machine instructions, this translation process is relatively straight-forward. The resulting
              file produced by the assembler, containing the machine specific binary instructions is called an
              <em>object file</em>
              and may be structured according to a particular
              <em>binary file format</em>
              (see §ABI and Binary File Formats -&gt; §§Binary File Formats) as required by the target platform where the built program is intended to
              run on.
            </p>
            <p>
              "
              <em>
                Even the simplest form of assembler performs two passes over the input. The first pass detects all the identifiers in the assembly
                code that denotes storage location and store them in the symbol table (other than compilers symbol table). The storage location is
                assigned to the identifier that is encountered in the first pass.
              </em>
            </p>
            <p>
              <em>
                In the second pass, the input is scanned again, and this time the operation code are translated into a sequence of bits representing
                that operation in the machine code. The second pass also translates identifiers into the addresses defined in the symbol table. Thus
                the second pass generates the relocatable machine code.
              </em>
              "
            </p>
            <p>
              "
              <em>
                Assemblers, in general, do not perform code optimization. They rarely optimize beyond choosing the shortest form of an instruction or
                filling delay slots. The machine code that comes out of an assembler is equivalent to the assembly instructions that go into the
                assembler. Some assemblers have high-level capabilities in the form of Macros.
              </em>
              "
            </p>
          </li>
          <li>
            <div>
              <strong>Linking</strong>
              :
            </div>
            <p>
              The source code of a working program needs not be stored in a single monolithic file, but may instead be store within separate smaller
              source files. This leads to the advantage of increased program modularity which helps developers in managing projects involving large
              and complex programs with great amounts of code. Another advantage of this fragmentation of source code is that it allows separate
              compilation, where different parts of the source may be compiled at different times and when modification of code in selected source
              files among the whole set occurs, only those files containing changes need to be recompiled instead of having all code belonging to the
              program be recompiled each time a change in the source occurs. As such, this is all made possible with the help of the linker module
              during the build process. In essence, the linker takes pieces of code in separate files and either merge or link them together to form a
              single executable program. During the build process, the input to the linker consists of previously compiled object files. The code
              within these object files may contain references to code within other object files that are also part of the program and would cause
              what are called unresolved external symbols. Here,
              <em>symbol</em>
              means functions and identifiers that have been declared in the source code and are subsequently considered as distinct entities. The
              term
              <em>unresolved external symbol</em>
              means a symbol that was previously declared but has not yet been assigned a
              <em>definition</em>
              . Thus, the linker takes all the constituent object files of a program and attempts to resolve all the unresolved external symbols by
              making use of a data structure called
              <em>symbol table</em>
              (See §Program Compilation Process; §§Symbol Table). A symbol table is found within each object file and contains all the symbols
              declared within that translation unit, as well as the address of code within the file corresponding to those symbols that are resolved.
              Once the linker has located all the relevant pieces of code needed to resolve all unresolved symbols encountered, these pieces of code
              are either all copied over to form a single executable file or they are linked with the translation unit containing the
              <em>main function</em>
              to form a dynamically linked executable file, that is the location of these pieces of code are provided so that at program load time or
              during program run time, these pieces of code can be found and executed.
            </p>
          </li>
        </ol>
      </ki-topic>
      <ki-topic id="execution-process" name="Execution Process">
        <ki-reflist>
          <ki-ref link="https://inst.eecs.berkeley.edu/~cs61c/sp10/lec/19/2010SpCS61C-L19-ddg-RunProgII.pdf"></ki-ref>
          <ki-ref link="https://www.tenouk.com/ModuleW.html"></ki-ref>
        </ki-reflist>
      </ki-topic>
    </ki-topic>
    <ki-topic id="interpreted-model" name="Interpreted Model">
      <ki-reflist>
        <ki-ref link="https://www.techopedia.com/definition/7793/interpreter"></ki-ref>
        <ki-ref
          link="https://stackoverflow.com/questions/441824/java-virtual-machine-vs-python-interpreter-parlance#SEE_ANSWER_BY_ZarathustrA"></ki-ref>
        <ki-ref link="https://techdifferences.com/difference-between-compiler-and-interpreter.html"></ki-ref>
        <ki-ref link="https://en.wikibooks.org/wiki/Python_Programming/Interactive_mode"></ki-ref>
        <ki-ref link="https://en.wikipedia.org/wiki/Interpreter_(computing)"></ki-ref>
      </ki-reflist>
      <p>
        The interpreted model of program execution is an approach which provides direct execution of program code in text form without requiring it to
        be compiled or built beforehand. To implement this approach //to accomplish this//, a translation tool called an
        <em>interpreter</em>
        is used. The interpreter is a program which processes code in text form one statement at a time (in many cases, internally generating a
        corresponding syntax tree), immediately evaluates it, and then executes it by directing the CPU to perform equivalent machine instructions.
        This actively changes the state of the program while some of the previously encountered structures and statements are kept in memory. Using
        this approach, the input to the interpreter may be provided as a prior composed source file or it may be fed dynamically
        statement-by-statement, which is the “typical behavior demonstrated by scripting languages”, for example Bash, AWK, etc.
      </p>
    </ki-topic>
    <ki-topic id="hybrid-model" name="Hybrid Model">
      <p><em>[Partially unsanitized] //non trivial quotation containing uninvestigated info//</em></p>
      <ki-reflist>
        <ki-ref
          link="https://stackoverflow.com/questions/441824/java-virtual-machine-vs-python-interpreter-parlance#SEE_ANSWER_BY_ZarathustrA"></ki-ref>
        <ki-ref link="https://en.wikipedia.org/wiki/Interpreter_(computing)"></ki-ref>
        <ki-ref link="http://www.techdarting.com/2014/04/python-compiled-or-interpreted-language.html"></ki-ref>
        <ki-ref link="https://opensource.com/article/18/4/introduction-python-bytecode"></ki-ref>
      </ki-reflist>
      <p>
        Besides the build and execute model and the interpreted model, some language implementations actually adopts aspects of both approaches
        producing some hybrid execution models. For example, for a given language implementation, the source code may first be compiled into an
        intermediate representation of the program (such as into bytecode form, see §Types of Programming Languages by Level of Abstraction;
        §§Intermediate Language/Representation), and then this intermediate representation may be fed to an interpreter (in the case of bytecode, this
        would be a virtual machine) for execution. The advantages provided by this approach would be better portability of programs relative to
        compiled code, as well as better execution performance and efficiency than interpreted code, although it’s execution performance and
        efficiency does not surpass that of compiled code. This is the model adopted by the default implementation of Java. Another case of hybrid
        execution model “
        <em>
          is just-in-time compilation (JIT), a technique in which the intermediate representation is compiled to native machine code at runtime. This
          confers the efficiency of running native code, at the cost of startup time and increased memory use when the bytecode or AST is first
          compiled. Adaptive optimization is a complementary technique in which the interpreter profiles the running program and compiles its most
          frequently executed parts into native code. Both techniques are a few decades old, appearing in languages such as Smalltalk in the 1980s.
          Just-in-time compilation has gained mainstream attention among language implementers in recent years, with Java, the .NET Framework, most
          modern JavaScript implementations, and Matlab now including JITs.
        </em>
        ”
      </p>
    </ki-topic>
  </ki-topic>
  <ki-topic id="program-compilation-process" name="Program Compilation Process">
    <ki-reflist>
      <ki-ref link="https://en.wikipedia.org/wiki/Compiler"></ki-ref>
      <ki-ref link="https://www.youtube.com/watch?v=cToJ_FexgIA&amp;list=PLWPirh4EWFpGa0qAEcNGJo2HSRC5_KMT6&amp;index=5&amp;t=0s"></ki-ref>
      <ki-ref link="https://en.wikipedia.org/wiki/Abstract_syntax_tree"></ki-ref>
      <ki-ref link="https://eli.thegreenplace.net/2009/02/16/abstract-vs-concrete-syntax-trees"></ki-ref>
      <ki-ref link="https://en.wikibooks.org/wiki/GNU_C_Compiler_Internals/GNU_C_Compiler_Architecture"></ki-ref>
      <ki-ref link="https://en.wikipedia.org/wiki/GNU_Compiler_Collection#GENERIC_and_GIMPLE"></ki-ref>
      <ki-ref link="https://docs.microsoft.com/en-us/cpp/preprocessor/phases-of-translation?view=vs-2019"></ki-ref>
      <ki-ref link="http://www.geoffchappell.com/studies/msvc/language/preprocessor/tokens/index.htm"></ki-ref>
      <ki-ref link="https://techdifferences.com/difference-between-compiler-and-assembler.html"></ki-ref>
      <ki-ref link="https://www.geeksforgeeks.org/need-for-intermediate-code-and-code-optimization/?ref=leftbar-rightbar"></ki-ref>
    </ki-reflist>
    <p>
      The compilation process involves transforming some given input source code (usually in high-level language form) into machine instructions
      (either in assembly form or in binary form). However, the set of functions performed by the compilation phase during program translation is not
      universally defined, as it may vary according to different compilation tools. For example, in the overall program build process, the original
      source file may undergo a distinct preprocessing phase prior to compilation in some program translation toolsets, while in others preprocessing
      may be handled by their compilation modules (e.g. in GCC, the C language preprocessor is implemented as a part of the lexer). Also, in some
      toolsets, the output of the compiler may be machine instructions in the form of assembly code which need to to be further processed by an
      separate assembler utility to produce binary code stored as object files (e.g. GCC) , while in other toolsets, the compiler may output binary
      machine instructions directly without requiring a separate assembler (e.g. Microsoft C/C++ Compiler). Despite these differences, compilers in
      general commonly perform a set of usual tasks. These are lexical analysis, syntax analysis, semantic analysis, intermediate code production,
      machine independent optimizations, machine dependent optimizations and target code generation. Although, intermediate code production and
      optimizations may be omitted by some compilers.
      <span style="color: red">
        As a compiler goes through these phases the source code may be transformed into various intermediate representations to ease or enhance
        operations.
      </span>
      Concerning the implementation of these tasks, some of them may be performed concurrently, while others may be performed sequentially. Also,
      whether the processing of source code through some or all of theses phases occurs one statement at a time or occurs as units of whole files is
      of toolset design choice.
    </p>
    <p>
      One perspective that may be used to describe the compilation process is to group the phases of compilation into three stages, as the front end,
      the middle end and the back end. The front end consists of lexical analysis, syntax analysis, semantic analysis, and intermediate code
      production. The middle end consists of various analyses upon the intermediate representation of the source code and of machine independent code
      optimizations. The back end consists of machine dependent code optimizations and of target code generation. //During the course of compilation,
      it is considered good practice and design for compilers to emit detailed and useful error messages using a well implemented error handling
      system should unexpected issues arise. It is also common for compilers to create and maintain auxiliary data structures called symbol tables
      first created during the front end stage of compilation, which contain the name and type of all identifiers encountered in the code with
      possibly some other information. Symbol tables facilitates numerous tasks that compilers perform and as compilation progresses through the
      phases modifications may be applied to the tables and additional information may be added. //
    </p>
    <ki-topic id="program-compilation-front-end" name="Phases of the Front End">
      <div>
        <ul>
          <li>
            <strong>Preprocessing (potentially)</strong>
            : In cases where preprocessing is implemented as part of the compilation process, the following tasks are performed on the source code.
            Removal of comments and non useful white-spaces, line reconstruction and execution of preprocessing directives which may include
            conditional code exclusion, macro substitution and etc. In some cases, preprocessing may be performed concurrently with other phases (e.g.
            In GCC, the C language preprocessor is implemented as a part of the lexer. This seems also to be the case for the Microsoft C/C++
            compiler.).
          </li>
          <li>
            <strong>Lexical analysis</strong>
            : This phase is also known as tokenization. The lexical analyzer reads the characters of source code and produces a stream of tokens. Each
            token consists of the pair of a token name and an optional token value and it represents the logical sequence of characters like keyword,
            identifiers, operators. The sequence of character that forms a token is called lexeme.
          </li>
          <li>
            <strong>Syntax analysis</strong>
            : This phase is also known as parsing. During this phase, the previously established stream of tokens is parsed to identify the syntactic
            structure of the program. This phase typically builds a concrete syntax tree (also known as parse tree) directly following the grammar of
            the source language, which replaces the linear structured sequence of tokens, but contains every element of the original source code
            including punctuation and etc. A concrete syntax trees is not very amenable to analysis and further processing, thus it is generally used
            to produce an abstract syntax tree (AST), which is a data structure that does not contain all the syntactic clutter and other non useful
            elements of the former. An AST “is often analyzed, augmented and transformed by later phases” of the compilation process.
          </li>
          <li>
            <strong>Semantic analysis</strong>
            : During this phase, the compiler checks for the semantic correctness of the program, reporting any error of semantic nature that are
            present in the source code. To illustrate the idea, consider the following examples. In C++ language, the statement “ int y = x/w; ” is
            both lexically and syntactically correct, however if the variable “ w “ was assigned the value of zero, then the expression is invalid
            (division by zero is undefined) and the statement would have a semantic error. Also, the C++ statement “ a = 6; “ is again lexically and
            syntactically correct, however it would constitute a semantic error if the variable “ a “ was declared as constant, since reassignment of
            constant variables is not allowed. To ensure that a piece of code is free of all semantic errors, a number of semantic checks need to be
            perform and these may vary between source languages since their specifications differ. These checks may include for example type checking
            which ensures that variables and functions used are of the right type, and in case that they are not, attempt to perform implicit
            conversion if possible, otherwise an error shall be raised. Another example which specifically applies to C++, is the need to ensure that
            an identifier is declared before use. Many of theses semantic checks may be facilitated by the use of a type of data structure maintained
            internally by the compiler and called “symbol table”. Symbol tables are generally created in one of the phases among lexical analysis,
            syntax analysis and semantic analysis, and contain information about all the identifiers and literals that are encountered in the source
            code. They help with tasks such as type checking, verification of identifier declaration before use and etc. During the semantic analysis
            phase contextual and semantic information is added to the AST. It should be reiterated that although described as distinct phases, many of
            the tasks of the font end and of the compilation process in general may be performed concurrently and be carried out with a single pass
            over the code depending on compiler implementation and design.
          </li>
          <li>
            <strong>Intermediate code production</strong>
            : It should be noted that intermediate code generation and optimizations are not necessary tasks in the compilation process, as target
            code may be generated by directly evaluating the AST or it may be produced at an earlier stage using the parse tree by means of
            syntax-directed translation. However, performance of theses tasks provides benefits of great value, therefore these are common phases of
            the compilation process. In fact, optimizations renders the resulting target code faster and more efficient, while production of
            intermediate code allows components of a given compiler to be retargetable which makes the creation of compilers for various languages and
            various target platforms easier. As such, following the all the analysis phases of the front end, the AST is used to produced an
            intermediate code representation of the source program which would be subject to further processing by later phases of compilation.
          </li>
        </ul>
      </div>
    </ki-topic>
    <ki-topic id="program-compilation-middle-end" name="Phases of the Middle End">
      <div>
        <p>
          During the middle end stage of compilation the intermediate code produced by the front end is first analyzed and then machine independent
          optimizations are applied to it. Such optimizations do not depend on the target platform on which the resulting binary code from the
          translation process is intended to run on, therefore these optimizations and the modules of compiler preforming them “can be shared between
          multiple versions of the compiler supporting different target platforms”.
        </p>
        <p>
          “There is a trade-off between the granularity of the optimizations and the cost of compilation,” where local optimizations are quick to
          perform but only affect a small portion code, whereas interprocedural and program-wide optimizations may affect code in a greater scope, but
          requires more computational investments. “Due to the extra time and space needed for compiler analysis and optimizations, some compilers
          skip them by default and users have to use compilation options to explicitly tell the compiler which optimizations should be enabled.”
        </p>
        <p>
          At this stage of compilation, the optimized intermediate code may potentially be transformed again into other intermediate forms that are
          lower level representations of the translated program, depending on compiler implementation and design, before being passed on the the back
          end stage.
        </p>
        <ul>
          <li>
            <strong>Analysis</strong>
            : As “accurate analysis is the basis for any compiler optimization”, during the middle end, the intermediate code may undergo a variety of
            analyses which may include data-flow analysis, dependence analysis, alias analysis, pointer analysis, escape analysis, etc. “The control
            flow graph of every compiled function and the call graph of the program are usually also built during the analysis phase.”
          </li>
          <li>
            <strong>Machine independent code optimizations</strong>
            : Following associated analyses, the intermediate code/representation “is transformed into functionally equivalent but faster and/or more
            efficient forms”. “Examples of middle end optimizations are removal of useless (dead code elimination) or unreachable code (reachability
            analysis), discovery and propagation of constant values (constant propagation), relocation of computation to a less frequently executed
            place (e.g., out of a loop), specialization of computation based on the context”, inline expansion and etc.
          </li>
        </ul>
      </div>
    </ki-topic>
    <ki-topic id="program-compilation-back-end" name="Phases of the Back End">
      <div>
        <ul>
          <li>
            <strong>Machine dependent code optimizations</strong>
            : At the back end stage, the compiler may perform further analyses and apply optimizations on the code which are specific for the target
            platform. These may include for example peephole optimizations which replaces short sequences of machine instructions by functionally
            equivalent, but more efficient ones.
          </li>
          <li>
            <div>
              <strong>Target code generation</strong>
              : During this phase, the compiler uses the optimized intermediate representation of the translated program to produce the target code of
              the compilation process. The target code produced may be of various forms depending on the nature of the compiler. It might be bytecode,
              high level language code (e.g. C code), machine instructions in the form of either assembly code or binary code, and etc. Although in
              most common instances, the product of the compilation process is machine instructions in the form of assembly or binary code. In such
              cases, the generation of machine instructions “involves resource and storage decisions, such as deciding which variables to fit into
              registers and memory”, and involves “instruction scheduling, which re-orders instructions to keep parallel execution units busy by
              filling delay slots”. When the product of compilation is binary machine code, the output object file might have to adhere to a
              particular binary file format (See §ABIs and Binary File Formats; §§Binary File Formats).
            </div>
            <div>
              Auxiliary data structures such as those containing relocation and linking information, and debugging data may also be generated by the
              compiler and included in the output file. Example of such include symbol tables or reduced versions of these, relocation tables and file
              headers.
            </div>
          </li>
        </ul>
      </div>
    </ki-topic>
    <ki-topic id="symbol-table" name="Symbol Table">
      <ki-reflist>
        <ki-ref>[Book] Compiler Construction, Niklaus Wirth, 2005, pg. 40-42</ki-ref>
        <ki-ref link="https://en.wikipedia.org/wiki/Symbol_table"></ki-ref>
        <ki-ref link="https://www.geeksforgeeks.org/symbol-table-compiler/"></ki-ref>
        <ki-ref link="https://www.youtube.com/watch?v=oyG_JfrbTCQ"></ki-ref>
        <ki-ref link="https://inst.eecs.berkeley.edu/~cs61c/sp10/lec/18/2010SpCS61C-L18-ddg-RunProgI-6up.pdf"></ki-ref>
        <ki-ref link="https://inst.eecs.berkeley.edu/~cs61c/sp10/lec/19/2010SpCS61C-L19-ddg-RunProgII-6up.pdf"></ki-ref>
        <ki-ref link="https://www.youtube.com/watch?v=hoLYnS2jOV8"></ki-ref>
        <ki-ref link="https://stackoverflow.com/questions/8623884/gcc-debug-symbols-g-flag-vs-linkers-rdynamic-option"></ki-ref>
        <ki-ref link="https://blogs.oracle.com/solaris/inside-elf-symbol-tables-v2"></ki-ref>
      </ki-reflist>
      <ki-topic id="symbol-table-description" name="Description">
        <p>
          The symbol table is an important data structure that is used for various purposes during essentially all stages of a program’s execution
          life cycle starting from compilation to linking to dynamic linking (during load time and run time), as well as for debugging. In the current
          context, a “symbol” is defined as an identifier or a literal that is declared in the source code of some given program. The term “symbol
          table” “dates back to the time of assemblers, when identifiers were called symbols”. The symbol table contains an entry for every symbol
          appearing in the source code of a translated program, as well as for some intermediate expression values generated by the compiler and for
          statement labels. Each entry would contain information such as symbol name and some associated attributes like type, value, address and etc.
          Concerning the uses of the symbol table, during compilation, it is used for analysis of the source and for code generation. During linking,
          it is used for relocation purposes and for matching symbol declarations with symbol definitions between different compilation units. During
          dynamic linking, it provides the dynamic linker with information concerning the binding and loading of relevant pieces of code required for
          execution. During a debug session, it may provide information about the code currently under execution.
        </p>
        <p>
          It should be noted that the term “symbol table” used in different contexts may refer to different things. For example, in the context of
          program translation during compilation, the term would refer to a data structure that only exists in memory for the compiler’s internal use.
          Whereas in the contexts of linking and debugging, the term may refer to reduced or modified versions of those tables that were used during
          translation. These reduced/modified symbol tables contain less information for each entry (by excluding unnecessary information that is only
          needed for compilation) and are store within the object, library or executable files themselves.
        </p>
      </ki-topic>
      <ki-topic id="symbol-table-production" name="Production">
        <p>
          The symbol table is first created during the front end stage of program compilation. During the analyses phases of the front end, the
          compiler creates a new symbol table entry for each declaration that it parses. Before the entry would be added, the compiler needs to check
          though the table to ensure that the symbol is not already present. If it is so, it would signify a case of multiple declaration and
          constitute a programming error. “Every occurrence of an identifier in a statement also requires a search in the symbol table in order to
          determine the attributes (properties) of the object denoted by the identifier.” As such, along with the symbol name, the compiler stores
          additional attributes associated with such object for each entry of the symbol table. “A typical attribute is the object’s class. It
          indicates whether the identifier denotes a constant, a variable, a type or a procedure. A further attribute in all languages with data types
          is the object’s type” (e.g. string, integer, floating-point, etc.). Other attributes may include the object’s scope, dimension, line of
          reference and etc.
        </p>
        <p>
          “A compiler may use one large symbol table for all symbols or use separated, hierarchical symbol tables for different scopes. For example,
          in a scoped language such as Algol or PL/I a symbol "p" can be declared separately in several procedures, perhaps with different attributes.
          The scope of each declaration is the section of the program in which references to "p" resolve to that declaration. Each declaration
          represents a unique identifier "p". The symbol table must have some means of differentiating references to the different "p"s.”
        </p>
      </ki-topic>
      <ki-topic id="symbol-table-usage" name="Usage">
        <p>
          During the the front end stage of the compilation process, the symbol table is relied upon to perform semantic checks. This is done by
          looking up the attributes of a given symbol encountered in a statement and verifying that the usage of such symbol in that context does not
          break any semantic rule. A notable example is type checking where the “type” attribute of symbols is used to ensure that the types used in
          statements and expressions of the source code are consistent. Generation of intermediate code and code optimization processes also depend on
          information provided by the symbol table and during these phases, the symbol table is also used for holding additional entries associated
          with intermediate and temporary expression values. It is similarly employed for target code generation, where in addition, it also handles
          the address and relocation information of relevant symbols.
        </p>
        <p>
          When an object file is created by a compiler or an assembler, a reduced or modified version of the symbol table that was used during
          compilation is exported to the object file. This exported symbol table may not contain all the attributes that were previously present, but
          contains address or relocation information that may be later used by the linker to find the location of the symbol definitions within the
          object file. The exported symbol table would also contain information indicating whether the included symbols are defined or undefined, as
          well as information regard the class/type of the symbols (here “class/type” means such concepts as: function, variable, constant, etc.).
        </p>
        <p>
          During the linking process, through the use of information available in the exported symbol table of every compilation unit (i.e. object
          file) and library module provided for the build, the linker would attempt to resolve all undefined symbols that it encounters. Once the
          linking process is successfully completed, the linker would create an executable file. For further debugging purposes, the linker may store
          within the executable file an extensive version of symbol table created by merging the symbol tables of all object and library files that
          were used for the build, with all symbol definitions being resolved. Otherwise, such symbol table may be omitted to save storage space
          and/or for obfuscation purposes.
        </p>
        <p>
          In the case that the produced executable is one which is dynamically linked (meaning that some of the symbol definitions are bound to
          libraries at load time or run time), a symbol table different from the one provided for debugging purposes will be included in the
          executable file. It is called a “dynamic symbol table” and contains only those symbols which require load time or run time binding. Where
          the extensive version of symbol table can be stripped, the dynamic symbol table is usually not stripped from dynamically linked executables,
          since its removal would break the executables as the load time and run time linkers rely on it to perform their tasks. As such, depending on
          the nature of a given executable file, on the options used during its build process and on post-production processing, an executable file
          may contain both symbol tables or none.
        </p>
      </ki-topic>
      <ki-topic id="symbol-table-implementations" name="Data structure implementations">
        <p>
          “Numerous data structures are available for implementing symbol tables”, such as plain lists, linked lists, binary search trees and hash
          tables. The simplest data structure to implement is the plain linear list. When using linear lists, new entry insertion is fast, but entry
          look-up may get slow as the symbol table grows. Since the compiler front end “spends a great portion of its time looking up the symbol
          table”, the implementation choice of the latter “has a crucial effect on the overall speed of the compiler”. The symbol table “must be
          organized in such a way that entries can be found as quickly as possible”. For that matter, it is commonly implemented as hash tables, since
          the entry search time of a “hash table is independent of the number of elements stored within, making it efficient for a large number of
          elements.” Using this method, when a new symbol entry needs to be added, “the keyword or identifier is 'hashed' to produce an array
          subscript” which denotes the position of the entry within the data structure. Hash collisions are inevitable, where two different symbol
          names may hash to the same value. To deal with this issue multiples options are available. For example, instead of storing either entry of
          the colliding symbols, a pointer is placed in the hashed position. This pointer shall point to an auxiliary data structure containing the
          entries of both colliding symbols and should further symbols collide to the same value, they would be added consecutively to the auxiliary
          data structure.
        </p>
        <p>Below is a comparison of different data structures that may be use for symbol table implementations (the following list is quote):</p>
        <ol>
          <li>
            List:
            <ul>
              <li>In this method, an array is used to store names and associated information.</li>
              <li>A “guard element” pointer is maintained at end of all stored records and new names are added in the order as they arrive.</li>
              <li>
                To search for a name we start from beginning of list until guard pointer and if it is not found, an error “use of undeclared name” is
                raised.
              </li>
              <li>While inserting a new name we must ensure that it is not already present otherwise error occurs i.e. “Multiple defined name”.</li>
              <li>Insertion is fast O(1), but lookup is slow for large tables – O(n) on average.</li>
              <li>Advantage is that it takes minimum amount of space.</li>
            </ul>
          </li>
          <li>
            Linked List:
            <ul>
              <li>A link field is added to each record.</li>
              <li>Searching of names is done in order pointed by link of link field.</li>
              <li>A pointer “First” is maintained to point to first record of symbol table.</li>
              <li>Insertion is fast O(1), but lookup is slow for large tables – O(n) on average</li>
            </ul>
          </li>
          <li>
            Hash Table:
            <ul>
              <li>
                In hashing scheme two tables are maintained – a hash table and symbol table and is the most commonly used method to implement symbol
                tables..
              </li>
              <li>A hash table is an array with index range: 0 to tablesize – 1.These entries are pointer pointing to names of symbol table.</li>
              <li>To search for a name we use hash function that will result in any integer between 0 to tablesize – 1.</li>
              <li>Insertion and lookup can be made very fast – O(1).</li>
              <li>Advantage is quick search is possible and disadvantage is that hashing is complicated to implement.</li>
            </ul>
          </li>
          <li>
            Binary Search Tree:
            <ul>
              <li>For every node two link fields shall be provided i.e. left and right child.</li>
              <li>All names are created as child of root node that always follow the property of binary search tree.</li>
              <li>Insertion and lookup are O(log2 n) on average.</li>
            </ul>
          </li>
        </ol>
      </ki-topic>
      <ki-topic id="example-symbol-table-compiler" name="Example of compiler internal symbol table">
        <ki-reflist>
          <ki-ref link="https://en.wikipedia.org/wiki/Symbol_table#Example"></ki-ref>
        </ki-reflist>
      </ki-topic>
      <ki-topic id="example-symbol-table-binary-file" name="Example of binary file symbol table - SysV ABI">
        <ki-reflist>
          <ki-ref link="https://en.wikipedia.org/wiki/Symbol_table#Example:_SysV_ABI"></ki-ref>
        </ki-reflist>
      </ki-topic>
      <ki-topic id="example-symbol-table-python" name="Example - Python symbol table">
        <ki-reflist>
          <ki-ref link="https://en.wikipedia.org/wiki/Symbol_table#Example:_the_Python_symbol_table"></ki-ref>
        </ki-reflist>
      </ki-topic>
    </ki-topic>
    <ki-topic id="atypical-translation-processes" name="Atypical Translation Processes">
      <ki-reflist>
        <ki-ref link="https://en.wikipedia.org/wiki/Compiler#Types"></ki-ref>
      </ki-reflist>
      <p>
        Many different types of compilers (code translators) exist. Beyond the most common type of compiler, which takes a high level language source
        code and translates it into low level machine instructions, that is discussed extensively in this text, there exist also some atypical types
        of code translators such as the following:
      </p>
      <div>
        "
        <em>
          <ul>
            <li>A program that translates machine code to assembly language is called a disassembler.</li>
            <li>A program that translates from a low-level language to a higher level one is a decompiler</li>
            <li>
              A program that translates between high-level languages is usually called a source-to-source compiler, language converter, or language
              rewriter. The last term is usually applied to translations that do not involve a change of language.
            </li>
            <li>
              A program that rewrites object code back into the same type of object code while applying optimizations and transformations is a binary
              recompiler.
            </li>
          </ul>
        </em>
        "
      </div>
    </ki-topic>
    <ki-topic id="msvc" name="Case Study: Microsoft C/C++ Compiler">
      <div><em>[Partially unsanitized] //large amounts of unrefined quotation// //Inductions based on speculative assumptions//</em></div>
      <ki-reflist>
        <ki-ref link="https://en.wikibooks.org/wiki/X86_Disassembly/Assemblers_and_Compilers"></ki-ref>
        <ki-ref link="http://bytepointer.com/msvc/msvc8.htm"></ki-ref>
        <ki-ref link="http://www.geoffchappell.com/studies/msvc/cl/modules.htm"></ki-ref>
        <ki-ref link="https://docs.microsoft.com/en-us/cpp/preprocessor/phases-of-translation?view=vs-2019"></ki-ref>
        <ki-ref link="https://docs.microsoft.com/en-us/cpp/preprocessor/preprocessor?view=vs-2019"></ki-ref>
        <ki-ref link="http://www.geoffchappell.com/studies/msvc/language/preprocessor/tokens/index.htm"></ki-ref>
        <ki-ref link="https://docs.microsoft.com/en-us/cpp/build/reference/compiler-options-listed-alphabetically?view=vs-2019"></ki-ref>
        <ki-ref link="https://docs.microsoft.com/de-at/cpp/build/reference/e-preprocess-to-stdout?view=vs-2019"></ki-ref>
        <ki-ref link="http://www.geoffchappell.com/studies/msvc/cl/cl/options/fa.htm"></ki-ref>
        <ki-ref link="http://www.geoffchappell.com/studies/msvc/cl/cl/options/b$k.htm"></ki-ref>
        <ki-ref link="http://www.geoffchappell.com/studies/msvc/cl/cl/options/bk.htm"></ki-ref>
        <ki-ref link="https://docs.microsoft.com/de-at/cpp/build/reference/zs-syntax-check-only?view=vs-2019"></ki-ref>
        <ki-ref link="http://www.geoffchappell.com/studies/msvc/cl/cl/options/z$s.htm"></ki-ref>
      </ki-reflist>
      <p>
        The present treatise is partially based on the current author’s personal testing of the subject piece of software, therefore it is recommended
        to consult the testing folder “MSVC Stages Inspection” and the “README” draft notes within if more detailed descriptions of the software is
        desired. No claim or hypothesis made with respect to these tests have been completely validated by the results, therefore further inductions
        made based on these results may not represent the truth of the matter.
      </p>
      <p>
        The Microsoft C/C++ Compiler is distributed as part of a toolset called the Microsoft Visual C/C++ Build Tools which contains an assortment of
        programming utilities including dumpbin (“dumpbin.exe”) which is a binary file inspection tool, Microsoft Macro Assembler (“ml.exe” or
        “ml64.exe” for 32-bit and 64-bit target platforms respectively) and including most importantly for the current topic Microsoft Incremental
        Linker (“link.exe”) and Microsoft C/C++ Compiler Driver (cl.exe) and its associated modules. When using the Microsoft C/C++ Compiler, either
        through command-line or the Visual Studio IDE, commands are passed to the compiler driver “cl.exe” with the command “cl“ according to the
        syntax “cl [ option... ] filename... [ /link linkoption... ]”, then the compiler driver calls upon its associated modules as well as the
        linker to perform the actual job of compiling and building the target program while itself only serves as an interface of sorts. The working
        compiler program, excluding the driver, is composed of two separate modules, a compiler front end with a version specific for C code (c1.dll)
        and a version specific for C++ code (c1xx.dll), as well as a common compiler back end (c2.dll). Technically, there may also be a middle module
        in-between, but it is by default not used, not present in the installation directories and not officially documented, but can nevertheless be
        implemented in the compilation flow using a command line option. The absence of the middle module has no effective significance from an
        end-user perspective however, since it is intended to be left out by Microsoft and compilation works fine without. The compiler front-end
        seems to carry out the tasks of preprocessing, of lexical analysis and of syntax analysis. The front end seems to accomplish these tasks by
        performing the following actions:
      </p>
      <div>
        "
        <div>
          <em>Character mapping</em>
          :
          <p style="margin-top: 1em">
            Characters in the source file are mapped to the internal source representation. Trigraph sequences are converted to single-character
            internal representation in this phase.
          </p>
        </div>
        <div>
          <em>Line splicing</em>
          :
          <p style="margin-top: 1em">
            All lines ending in a backslash (\) immediately followed by a newline character are joined with the next line in the source file, forming
            logical lines from the physical lines. Unless it's empty, a source file must end in a newline character that's not preceded by a
            backslash.
          </p>
        </div>
        <div>
          <em>Tokenization</em>
          :
          <p style="margin-top: 1em">
            The source file is broken into preprocessing tokens and white-space characters. Comments in the source file are replaced with one space
            character each. Newline characters are retained.
          </p>
        </div>
        <div>
          <em>Preprocessing</em>
          :
          <p style="margin-top: 1em">
            Preprocessing directives are executed and macros are expanded into the source file. The #include statement invokes translation starting
            with the preceding three translation steps on any included text.
          </p>
        </div>
        <div>
          <em>Character-set mapping</em>
          :
          <p style="margin-top: 1em">
            All source character set members and escape sequences are converted to their equivalents in the execution character set. For Microsoft C
            and C++, both the source and the execution character sets are ASCII.
          </p>
        </div>
        <div>
          <em>String concatenation</em>
          :
          <p style="margin-top: 1em">
            All adjacent string and wide-string literals are concatenated. For example, "String " "concatenation" becomes "String concatenation".
          </p>
        </div>
        "
      </div>
      <div>
        <em>Lexical analysis</em>
        :
        <p style="margin-top: 1em">
          The validity of each sequence of characters between white-space characters is verified according to language rules. The internal
          representation of the source is subsequently further updated.
        </p>
      </div>
      <div>
        <em>Syntax analysis</em>
        :
        <p style="margin-top: 1em">
          The validity of source program statements is verified according to language grammar. The internal representation of the source is
          subsequently further updated.
        </p>
        <p style="margin-top: 1em">
          When the compiler front-end finishes its actions, it outputs a series of temporary files which contain intermediate representations of the
          source program which are normally deleted upon return of the “cl” command. However by specifying the “/Bk” option when running the “cl”
          command, the temporary files are kept after compilation or build.
        </p>
      </div>
      <p>
        The compiler back end picks up where the front-end left off and seems to carry out the tasks of semantic analysis, code optimization and code
        generation. The back end module takes as input the temporary intermediate representation files produced by the front end and it may also
        generate temporary files of its own. If the user wishes to keep these temporary files, the compiler option “/Bk” (note it is not “/BK”) may be
        used to that effect, although it also disables the front end module. Concerning the code generation stage, multiple findings and some logical
        induction point to the likely fact that the internal intermediate representation of the source program is translated directly into binary
        code, without passing through an assembly form that is subsequently assembled into binary code. However, if assembly code is explicitly
        requested, then the compiler would produce it by disassembling the binary code. The logical induction that hints at this arrangement could be
        stated as that it would be more efficient to have the code take route #1: (1)intermediate representation --&gt; (2)binary form --&gt;
        (3)undergo machine dependent optimizations --&gt; (4)assembly form (optional), compared to route #2: (1)IR --&gt; (2)assembly form (mandatory)
        --&gt; (3)undergo machine dependent optimizations --&gt; (4)binary form, and compared to route #3: (1)IR --&gt; (2)lower-level IR --&gt;
        (3)undergo machine dependant optimizations --&gt; (4)binary form or assembly form (on request). In fact, under usual circumstances where the
        end user expects a binary object file as the result of compilation, route #1 would be the superior implementation since it only takes 3
        conceptual steps (by omitting assembly generation) to reach the goal as compared to 4 conceptual steps for route #2 and route #3 (all this is
        assuming that these are the most likely implementations). It should be noted that such a justification would not hold ground if, as a premise,
        the design philosophy is aimed at having retargetable modules capable of supporting various target platforms, but this is not the case for the
        MS compiler, as per a Wikibooks web page, “Microsoft's compiler only supports Windows systems, and Intel-compatible 16/32/64 bit
        architectures”. One of the findings that supports the stated claims is that the “/FA” and “Fa” compiler options have only been added with the
        release of Visual C++ version 14 (bundled with Visual Studio 8 / 2005). These options have the effect of explicitly requesting the production
        of assembly listing files from the compiler along with the usual binary object files (and executable files if the linker is invoked), and thus
        this suggests that prior versions are only able to emit binary object code files and didn’t have the ability to emit assembly listing files to
        the end-user. Another finding, which hints that the MS compiler does not convert assembly code to binary form internally, is that the compiler
        does not recognize the source file type when an assembly source file is given as input and consequently was not able to assemble such source
        file into and object file. Finally, it shall be noted that there exists another facility within the MSVC toolset called the Microsoft Macro
        Assembler or MASM (“ml.exe” or “ml64.exe” for 32-bit and 64-bit target platforms respectively) that operates independently of the MS compiler
        and its modules. MASM has the explicit function of assembling assembly code into binary code. If the MS compiler also have such functionality,
        then the presence of MASM could be regarded as redundant.
      </p>
    </ki-topic>
  </ki-topic>
  <ki-topic id="program-linking-process" name="Program Linking Process">
    <ki-reflist>
      <div><strong>Introduction to linkers and their place in the grand scheme</strong></div>
      <ki-ref link="https://www.tenouk.com/ModuleW.html">The most complete overview the “program linking” topic with full context by Tenouk.</ki-ref>
      <ki-ref link="http://www.lurklurk.org/linkers/linkers.html">
        Detailed overview of the “program linking” topic with treatise on differences between the GNU/Linux and the MS Windows platforms.
      </ki-ref>
      <ki-ref link="https://www.linuxjournal.com/article/6463">Detailed overview of the “program linking” topic on the GNU/Linux platform.</ki-ref>
      <div><strong>Introduction to linkers</strong></div>
      <ki-ref
        link="https://web.archive.org/web/20200307001527/http://www-inst.eecs.berkeley.edu/~cs162/sp06/hand-outs/p149-presser-linker-loader.pdf">
        Discussion about linkers and their functions and purposes from the ground up.
      </ki-ref>
      <ki-ref link="https://en.wikipedia.org/wiki/Relocation_(computing)">About relocations.</ki-ref>
      <ki-ref link="https://en.wikipedia.org/wiki/Loader_(computing)">About loaders.</ki-ref>
      <ki-ref link="https://inst.eecs.berkeley.edu/~cs61c/sp10/lec/19/2010SpCS61C-L19-ddg-RunProgII-6up.pdf">
        Succinct overview of the program linking process. (B&amp;W slides, multiple per page)
      </ki-ref>
      <ki-ref link="https://inst.eecs.berkeley.edu/~cs61c/sp10/lec/19/2010SpCS61C-L19-ddg-RunProgII.pdf">
        Succinct overview of the program linking process. (colored slides)
      </ki-ref>
      <div><strong>Program linking on the Solaris platform (Unix family, ELF-based)</strong></div>
      <ki-ref link="https://docs.oracle.com/cd/E19683-01/816-1386/index.html">Solaris 9, Linkers and Libraries Guide, index.</ki-ref>
      <ki-ref link="https://docs.oracle.com/cd/E19683-01/816-1386/6m7qcobk8/index.html">
        Solaris 9, Linkers and Libraries Guide, Ch. 1: Introduction to the Solaris Linkers.
      </ki-ref>
      <ki-ref link="https://docs.oracle.com/cd/E19683-01/816-1386/6m7qcobkd/index.html">
        Solaris 9, Linkers and Libraries Guide, Ch. 2: Link-Editor.
      </ki-ref>
      <ki-ref link="https://docs.oracle.com/cd/E19683-01/816-1386/6m7qcobkm/index.html">
        Solaris 9, Linkers and Libraries Guide, Ch. 3: Runtime Linker.
      </ki-ref>
      <ki-ref link="https://en.wikipedia.org/wiki/Direct_binding">About direct binding.</ki-ref>
      <ki-ref link="https://archive.is/20130722014755/http://blogs.oracle.com/roller/page/msw/20050614">About direct binding.</ki-ref>
      <ki-ref link="https://bugs.gentoo.org/114008">An obsolete port of the direct binding feature from Solaris to GNU/Linux Gentoo distro.</ki-ref>
      <div><strong>General treatise on dynamic linking</strong></div>
      <ki-ref link="https://web.archive.org/web/20091027232202/http://www.iecc.com/linker/linker10.html">
        Chapter 10 of John Levine’s book Linkers and Loaders titled Dynamic linking and loading. Detailed treatise about dynamic linking with
        discussion about differences between the GNU/Linux and the MS Windows platforms.
      </ki-ref>
      <ki-ref link="https://web.archive.org/web/20090414090621/http://www.iecc.com/linker/linker10fig.html">
        List of figures for Ch. 10 of J. Levine’s Linkers and Loaders.
      </ki-ref>
      <ki-ref link="https://web.archive.org/web/20090515133540/http://www.iecc.com/linker/linkerfig10-02.html">
        Figure showing the structure of a dynamically linked ELF file.
      </ki-ref>
      <ki-ref link="https://web.archive.org/web/20090513104606/http://www.iecc.com/linker/linkerfig10-01.html">
        Figure showing the flow of a library function call from an executable on an ELF-based system.
      </ki-ref>
      <div><strong>Program loading and Dynamic linking on the MS Windows platform</strong></div>
      <ki-ref link="https://www.youtube.com/watch?v=JPQWQfDhICA">About Windows DLLs.</ki-ref>
      <ki-ref link="https://en.wikipedia.org/wiki/Dynamic-link_library">About Windows DLLs.</ki-ref>
      <ki-ref
        link="https://community.broadcom.com/symantecenterprise/communities/community-home/librarydocuments/viewdocument?DocumentKey=d0e6af9a-2271-4aa1-b698-b09a1c103f9f&amp;CommunityKey=1ecf5f55-9545-44d6-b0f4-4e4a7f5f5e68&amp;tab=librarydocuments">
        Notes on the differences between shared libraries on the Windows platform and the GNU/Linux platform.
      </ki-ref>
      <ki-ref link="https://www.cs.toronto.edu/~arnold/427/18s/427_18S/indepth/dirty-cow/demo.html">
        An illustrated demonstration of a Linux system vulnerability called “Dirty COW” exploiting an implementation of COW using a race condition.
        This is completely unrelated to Windows DLLs and serves simply as an example to show the concept of copy-on-write.
      </ki-ref>
      <ki-ref link="http://sandsprite.com/CodeStuff/Understanding_imports.html">
        Some details about the Import Address Table used in the Windows dynamic/shared library system.
      </ki-ref>
      <ki-ref link="https://repo.zenk-security.com/Linux%20et%20systemes%20d.exploitations/Windows%20Internals%20Part%201_6th%20Edition.pdf">
        Windows Internals 6th ed. Pt.1, by Microsoft: Operating system manual. See pg. 369-371, 386: Describes process creation and program loading on
        MS Windows.
      </ki-ref>
      <div><strong>Dynamic linking on the GNU/Linux platform (Unix family, ELF-based)</strong></div>
      <ki-ref link="https://developer.ibm.com/tutorials/l-dynamic-libraries/">
        About shared libraries on the GNU/Linux platform with examples of the the “dynamic loading” feature using the “dl API” provided by the header
        file &lt;dlfcn.h&gt;.
      </ki-ref>
      <ki-ref link="https://refspecs.linuxfoundation.org/ELF/zSeries/lzsabi0_zSeries/x2251.html">
        About dynamic linking on the GNU/Linux platform with details about the usage of the GOT and PLT.
      </ki-ref>
      <ki-ref link="https://docs.oracle.com/cd/E23824_01/html/819-0690/chapter6-74186.html">
        About the Global Offset Table (GOT) used on ELF-based platforms.
      </ki-ref>
      <ki-ref link="https://docs.oracle.com/cd/E23824_01/html/819-0690/chapter6-1235.html">
        About the Procedure Linkage Table (PLT) used on ELF-based platforms.
      </ki-ref>
      <div><strong>Detailed references on the “program linking” topic</strong></div>
      <ki-ref link="https://www.iecc.com/linker/">
        Quality book on the topic of program linking by John Levine. Available in PDF format locally from files linkers_and_loaders - J. Levine
        (CROPPED TEXT &amp; FIGURES).pdf and linkers_and_loaders - J. Levine (UNCROPPED).pdf
      </ki-ref>
      <ki-ref link="https://www.airs.com/blog/page/4?s=linkers">
        Detailed essays on the GNU/Linux (ELF system) linking process by Ian Lance Taylor (creator of GNU Gold linker), index.
      </ki-ref>
      <ki-ref link="https://www.airs.com/blog/archives/38">Linkers, art. 1, by I.L. Taylor: Author’s introduction and topic introduction.</ki-ref>
      <ki-ref link="https://www.airs.com/blog/archives/39">Linkers, art. 2, by I.L. Taylor: Topic introduction continued.</ki-ref>
      <ki-ref link="https://www.airs.com/blog/archives/40">Linkers, art. 3, by I.L. Taylor: About address spaces and object file formats.</ki-ref>
      <ki-ref link="https://www.airs.com/blog/archives/41">
        Linkers, art. 4, by I.L. Taylor: About shared libraries with important details on GOT and PLT.
      </ki-ref>
      <ki-ref link="https://www.airs.com/blog/archives/42">Linkers, art. 5, by I.L. Taylor: More on shared libraries and about ELF symbols.</ki-ref>
      <ki-ref link="https://www.airs.com/blog/archives/43">
        Linkers, art. 6, by I.L. Taylor: About relocations and position dependent vs. position independent shared libraries.
      </ki-ref>
      <ki-ref link="https://www.airs.com/blog/archives/45">Linkers, art. 8, by I.L. Taylor: About ELF segments and ELF Sections.</ki-ref>
      <ki-ref link="https://www.airs.com/blog/archives/46">
        Linkers, art. 9, by I.L. Taylor: About symbol versions and relaxation optimization.
      </ki-ref>
      <ki-ref link="https://www.airs.com/blog/archives/48">Linkers, art. 11, by I.L. Taylor: About ELF archives (i.e. static libraries).</ki-ref>
      <ki-ref link="https://www.airs.com/blog/archives/50">
        Linkers, art. 13, by I.L. Taylor: More on symbol versions and compatibility and about static linking vs. dynamic linking.
      </ki-ref>
      <ki-ref link="https://www.airs.com/blog/archives/51">
        Linkers, art. 14, by I.L. Taylor: About link time optimizations and initialization code
      </ki-ref>
      <ki-ref link="https://www.airs.com/blog/archives/53">
        Linkers, art. 16, by I.L. Taylor: About template instantiation and about stack manipulation during exception handling.
      </ki-ref>
      <div><strong>Extras and late finds</strong></div>
      <ki-ref link="https://www.computerhope.com/unix/uld.htm">
        Search for string “Generate relocatable output”. About partial linking and object file as linker output.
      </ki-ref>
      <ki-ref link="https://docs.microsoft.com/en-us/cpp/build/walkthrough-creating-and-using-a-static-library-cpp?view=vs-2019">
        Hint about MS Window .lib archiver.
      </ki-ref>
      <ki-ref link="https://docs.microsoft.com/en-us/cpp/build/reference/structure-of-a-library?view=vs-2019">
        Hint about MS Window .lib archiver.
      </ki-ref>
      <ki-ref link="https://docs.microsoft.com/en-us/cpp/cppcx/static-libraries-c-cx?view=vs-2019">Hint about MS Window .lib archiver.</ki-ref>
    </ki-reflist>
    <ki-topic id="intro-to-linking-loading" name="Introduction to Program Linking and Loading">
      <p>
        Linking is the process of combining multiple pieces of precompiled code into a single output target. Most commonly, the output is a coherent,
        executable program. When such program is executed, all of its parts are normally mapped into a single memory address space. In present times,
        linking is an essential and indispensable part of a typical program actualization flow along with source code production and code compilation,
        however that has not always been the case. In fact, linking is not necessary to produce a well formed, executable program on any given
        computer system since every machine instruction constituting such a program may be generated from its source code. Thus, such program may be
        created by compiling or assembling the source code without requiring to be linked. On the other hand, the prevalence of program linking is
        largely due to an important benefit enabled by the linking process, separate compilation. This is the ability to compile different parts of a
        program at different moments as opposed to all at once. In addition to the obvious advantage of increased flexibility over when compilation
        occurs, separate compilation also allows the programmer to change and recompile only a part of a large program without recompiling the whole,
        which significantly reduces development time. Furthermore, the increased modularity offered by separate compilation also allows better code
        reuse, since some given precompiled piece of code may be linked into various different programs.
      </p>
      <p>
        The input to the linking process may be binary object files (see §Types of Program Codes; §§Object Code) and library files (see §Types of
        Program Codes; §§Libraries) which are produced from a collection of object files. The output of the linking process are generally either an
        executable program, a shared library or another object file. (Note that depending on the type, libraries files are not strictly produced by
        the linker as other tools may be used for their creation.) (Note that static libraries are not produced by linker. They are instead produced
        by “archivers”.) The program which perform the linking is called a “linker” and different types of linkers exist performing different types of
        linking. A linker whose output is directly mapped into memory and not saved to a file can be called a relocating loader. However, the termed
        “loader” in the modern setting is actually used to refer to programs which do no linking but simply map an executable or a shared library into
        system memory, as in modern systems the linking and the loading of programs are usually done at separate phases. In many systems such as
        GNU/Linux and MS Windows, the functions of the loader are carried out by parts of the operating system kernel. [Ref.25] A linker that creates
        and links a target (i.e. executable, object file or shared library) before the latter is invoked to be loaded into memory can be called “link
        editor”. A linker that performs linking on a target (i.e. executable or shared library only for this case) at the time when or after the
        latter is invoked to be loaded into memory can be called “dynamic linker”. The dynamic linker may be a standalone system tool such as in the
        case of the GNU/Linux platform or its functions may be handled by a part of the OS kernel such as in the case of MS Windows. [Ref.25] Two
        distinct paradigms of program linking exist.
      </p>
      <p>
        The first is static linking, whereby the link editor produces a target output (i.e. executable, shared library, or object file) by physically
        copying and combining required parts of the inputs, such as code and data that are referenced. In the case that the output is an executable or
        a shared library, it entails that such output is also self-contained and does not reference code or data defined in another module. Therefore,
        it is ready to be loaded and mapped into memory for execution without requiring any further alteration by other tools. In the case that the
        output is an object file, the link procedure may also be termed as partial linking. Although such output object file may contain some
        undefined references which could potentially be satisfied by definitions located in other modules, it is not intended to be processed by the
        dynamic linker. Instead, it as any other object file is intended to be once more the input to the link editor or any other tool suitable for
        manipulating object files.
      </p>
      <p>
        The second paradigm is dynamic linking, whereby one or more shared libraries are supplied as part of the input to the link edit procedure.
        Definitions of code and data located within input shared libraries which satisfy some references in the target output are not copied nor
        physically combined into the output. Instead information and data structures specifying how and where these definitions can be located are
        recorded in the target output. The type of such output may either be an executable or a shared library. When such an executable or shared
        library is loaded into memory for execution, it requires the dynamic linker to also load its dependencies which are the modules containing the
        missing definitions to its references. The dynamic linker shall then make alterations as necessary to all loaded modules that require
        adjustments (including the initial executable or shared library), so that every instruction and reference of all loaded elements work
        correctly. All other input elements (such as object files) supplied to the same link edit procedure which are not shared libraries shall be
        linked statically as described previously.
      </p>
    </ki-topic>
    <ki-topic id="static-linking" name="Static Linking">
      <p>
        Static linking is the simpler of the two above-mentioned linking paradigms and it historically preceded dynamic linking. It involves supplying
        as input two or more pieces of precompiled code in a suitable binary file format (See §ABIs and Binary File Formats; §§Binary File Formats) to
        a link editor which uses them to produce a self-contained executable program, a shared library or an object file. Common types of file used as
        input to a static link are object files and static libraries. (Possibly, shared libraries may be used, although this is unclear to the
        author.) As stated above, a notable feature of the target output is that all previously undefined references to code and data that have been
        resolved by the link edit procedure have their associated definitions copied and combined into the output.
      </p>
      <p>
        The mechanisms by which the link editor accomplished this task shall hereby be discussed. Since according to many binary file format
        specifications, a static library is in effect a container for a collection of individual object files and a dynamic library is in effect a
        single file resulting from an amalgamation of object files, which contains many of the same data structure as an object file, the treatment of
        object files shall be the main focus of discussion. Various binary file formats usually specifies object files to have certain common data
        structures and features. An example of these is the division of file content into “sections” such as a “text” section which contains program
        instruction code, a “data” section which contains the value of global or static variables, a “debug” section which contains debugging
        information, and etc. Object files also usually contain one or more headers, which provide information about where each section or other data
        structures are located within the file. Moreover, object files contain one or more symbol tables (see §Program Compilation Process; §§Symbol
        Table) which list all symbols referenced in the code contained within the file, indicate whether each symbol is defined and if it is, specify
        where the definition is located within the file. Object files also contain a list of relocations which indicates places in the text section
        where an address needs to be patched to enable proper program execution. When the link editor is supplied with two or more input object files,
        it uses the object file headers to find the sections within each file and concatenates like sections together to the output. [Ref.7] It
        combines the symbol tables of the inputs together to form one or more merged symbol tables in the output. It performs all the required
        relocations with respect to the final layout of the output by consulting the lists of relocations. [Ref.7] It verifies whether every symbol of
        the output has been defined or satisfied. If a symbol is undefined and a definition cannot be found within the object files, then the linker
        searches within the input library files if it is provided with any for a corresponding definition. If the target output of the link edit is an
        executable and if at the end of the symbol lookups, one or more symbols remain undefined, this constitutes a fatal error and the current link
        procedure is deemed to have failed. Finally the output is supplied with a new header which specifies the new layout.
      </p>
      <p>
        As mentioned above, library files may be supplied for a given link procedure in order to satisfy undefined symbol references. In the case of
        static linking, usually static libraries are used. A static library is in effect, a container with a collection of individual object files
        within. As such, when an undefined symbol in the target output of the link is satisfied by a definition located within one of the objects
        files contained in a static library, that particular object file is pulled from the library and treated as if it was supplied directly to the
        linker as an individual file. [Ref.2] Note that such an object file pulled from a library may itself include symbols that have not yet been
        defined and these also have to be satisfied. This entails that linking with one library may possibly require other libraries to included in
        the link as well. [Ref.2] The potential chains of newly included undefined symbols have some interesting implications. For example, some
        undefined symbol arising from an object file pulled in from a library may be resolved by a definition located within a second object file in
        the same library. Also, when multiple libraries are used for a link, the object files pulled from these may all contain symbols that are
        defined in one of the other libraries, which would require certain libraries to be reprocessed by the linker one or more times or be
        resupplied manually by user to the linker one or more times. How the linker handles these issues depends on the platform where the linker
        operates and on the linker itself. (For details on this, see Ref.2 and Ref.11.) [Ref.2] [Ref. 11] In theory, a shared library should also be
        able to be used as input to a static link, however whether this is actually possible and implemented on various platforms is unclear to the
        present author. (May review Refs for details or conduct new research.)
      </p>
    </ki-topic>
    <ki-topic id="dynamic-linking" name="Dynamic Linking">
      <p>
        Another linking paradigm is dynamic linking, whereby the output of the link edit procedure is either an executable or a shared library. The
        inputs to the link edit need to include at least one shared library. Dynamic linking differs from static linking in that when an undefined
        code or data reference is satisfied by a definition within an input shared library, the definition is not copied and combined into the target
        output. Instead some additional data structures are established within the target output where at least the name or an identifier associated
        with the shared library which provided the definition is record. Depending on the platform and on the system implementation, additional
        information may be recorded as well, such as the version number of the shared library, the path where the library is located, the name and
        path of the dynamic linker to be later invoked and etc. Any other elements that are supplied as input to the same link edit procedure that are
        not shared libraries are to be linked statically. Therefore dynamic linking specifically describes the relationship between an executable or
        shared library which references externally defined code and/or data and another shared library which provides said definitions. As such the
        latter becomes a dependency of the entity containing the references. When a dynamically linked executable produced by the link editor is
        invoked for execution, the loader loads and maps the process image from the executable into memory, sets up the process, but does not jumps
        immediately to the start of the program instructions. Instead the dynamic linker (which may be part of the OS kernel itself) is invoked
        beforehand. The dynamic linker goes through the list of the executable program’s dependencies and if one the dependencies is already loaded in
        memory at a prior time and if it is suitable for reuse, the dynamic linker patches up that dependency in-memory if necessary and maps it to
        the executable program’s address space, otherwise the dependency is loaded from storage. In this fashion, the dynamic linker loads and maps
        all dependencies of the executable and does the same iteratively if the dependencies have dependencies of their own until no more is left. If
        one or more dependencies fail to be loaded and/or mapped for any reason which may include it being missing, unusable or inaccessible, then
        this constitutes a runtime error. When all dependencies have been mapped into memory, the dynamic linker performs relocation fixes as
        necessary to all modules, which generally involves resolving and binding the symbols (i.e. identifiers for code and data) (see §Program
        Compilation Process; §§Symbol Table) of the program (such is the case for GNU/Linux). Some category of symbols may be bound at later time if a
        “lazy binding” option is in effect or all symbols could be bound at module load/map time if an “immediate binding” option is in effect.
        (Either may the default on some given system.) Once the required relocations and symbol bindings are completed, the dynamic linker hands back
        control and execution goes to the start of the program instructions.
      </p>
      <p>
        Many systems such as GNU/Linux and MS Windows also offer an alternative to the dynamic linking approach enabled by the link editor, by
        allowing dynamic linking to occur interactively using some API function calls directly in the program source code. These function calls
        interact directly with the OS kernel and system tools so as to allow dependencies to be load and unloaded during program runtime without
        needing to specified them to the link editor. As such, this approach is often called “delayed loading”, “delayed linking” or the like. After a
        dependency is loaded in this manner, the code and data that it contains are accessed through pointers which are returned by certain functions
        of the API.
      </p>
      <p>
        When a shared library is produced, the instruction code that it contains may be in a form which is “position dependent”, that is once the
        library is loaded into memory and relocations have been performed, it may not be mapped at a different memory address range within another
        process’s virtual memory address space. If some other process also requires the same library, another instance of the library needs to be
        created in the physical memory. The original instance of the loaded library may only be shared with another program if the memory address
        range occupied by that instance of the library is also free and available to be populated within the virtual memory address space of the
        second program. On the other hand, the instructions within a shared library may also be in a form which is “position independent”, that is
        once a single instance of such a library is loaded into physical memory, it may be shared between different processes even if it needs to be
        mapped at different virtual memory address ranges. Instructions of this nature is also known as PIC (position independent code).
      </p>
      <p>
        Shared libraries on the MS Windows platform, also known as DLLs (dynamically linked library), can only be created in a position dependent
        form. One advantage of this approach is that such code has minimal runtime performance overhead. However, a noticeable disadvantage of this
        approach compared to PIC is that when the shared library is used by multiple processes simultaneously, the memory consumption is greatly
        increased in practise.
      </p>
      <p>
        Shared libraries on the GNU/Linux platform may be produced in either a position dependent form or a position independent form. When the
        position dependent form is used, the implications are as described previously. On the other hand the GNU/Linux implementation of PIC in shared
        libraries is as follows. Relocations of external symbols are not made directly to the “text” section because all references to external symbol
        are redirected through auxiliary data structures. More precisely, whenever the program code needs to reference an external symbol,
        instructions using position-independent addressing (e.g. PC-relative instructions) are employed to access specific entries within special data
        structures located at fixed offsets from the start of the library module, meaning that such data structures are at a known distance from the
        text section. As such it shall be relevant to discuss what exactly are these data structures and what do they contain. In the case where the
        external symbol being referenced represents a global variable, the special data structure that is accessed is called “global offset table”
        (GOT) where its entries typically contain the value of external symbols, that is the address of the definitions. In the case where the
        external symbol being referenced is a function, the special data structure that is accessed is called a “procedure linkage table” (PLT) where
        most of its entries simply point to another entry in the GOT. If this is the case, it would be pertinent to ask what is the purpose of having
        this extra indirection. The answer to this question is the enabling of the “lazy symbol binding” mechanism. Before getting into the details of
        lazy binding, let us first examine the case where the immediate symbol binding option is in effect. In this situation, which as a side note is
        NOT the default setting on GNU/Linux, all symbol relocations and bindings occur at module load time and since each relocation have an
        associated GOT entry which is used to store the value of the symbols, once relocations are completed the GOT holds the value (i.e. address of
        the definition) of all external symbols referenced by the module. On the other hand, if lazy symbol binding is in effect, only relocations of
        external symbols that represent global variables are performed at load time and have their associated GOT entries populated with the relevant
        symbol value. Thus, the GOT entries associated with external symbols representing functions remain in an unresolved state until at some point
        during run time a module code instruction makes the first call to such externally defined function using the associated PLT entry which in
        turn points to the relevant GOT entry. When this happens the initial content of that GOT entry contains instructions that jump to various
        places in the code and push values onto the stack, but ultimately the dynamic linker is invoked which uses the values pushed onto the stack to
        identify the particular symbol to resolve. The dynamic linker then resolves and binds the symbol to its definition and patches up the GOT
        entry with the correct value, adjusting it so that the next time this GOT entry is accessed for a function call, execution jumps directly to
        address of the function code. When everything related to that symbol has been patched up, the dynamic linker itself jumps to the address of
        the function code and hands over execution so that execution flow resumes normally.
      </p>
      <p>
        All these intricacies of the GNU/Linux’s PIC shared library implementation make it possible to move symbol relocations from the text section
        to the GOT section. It should be noted that of all the significant module sections involved in this PIC implementation only the GOT section
        needs alteration and patching up, and thus read-write permission. The “text” and PLT sections are never modified and would be under read-only
        permission. As such, a single instance of a PIC shared library loaded into memory may share its “text” segment which includes the PLT section
        with multiple processes while each process would maintain its own local copy of the library’s “data” segment which includes the GOT section.
        Unsurprisingly, the main benefits and costs of PIC when compared to position dependent code is the opposite of those of the latter, as PIC may
        potentially provide significant memory savings at the expense of some runtime performance penalty.
        <span style="color: red">
          PIC also provides faster startup time since the loaded modules do not need to wait for all relocations to be performed before starting
          execution.
        </span>
      </p>
    </ki-topic>
    <ki-topic id="static-linking-v-dynamic-linking" name="Static Linking vs. Dynamic Linking">
      <p>
        Since in the static linking scheme the output of the link procedure physically contain the definition of the resolved symbols, they are more
        portable than dynamically linked modules. In fact, in the case of executables and shared libraries, only the statically linked module itself
        is required to allow execution, whereas when a dynamically linked module needs to be executed, one or more dependencies which provide the
        actual definitions to the external symbols referenced in the initial module also need to be available. Static linking also presents better
        startup time since it does not have the performance overhead associated with finding and loading dependencies.
      </p>
      <p>
        On the other hand, dynamic linking provides increased program modularity which have associated benefits such as easier deployment of changes,
        fixes and upgrades, since any dependency of a dynamically linked module may be swapped with a different version without requiring the
        dynamically linked module to be relinked with that new version and then to be redistributed. Such a new version of a given dependency may
        include changes, fixes and upgrades so long as its symbol signatures do not change. Dynamic linking also leads to a better resource usage
        profile when compared to static linking. In more details, if a given dependency is fully self-contained with no external symbol reference or
        if a given dependency does contain external symbol references (the definition of which may be provided by its parent or sub-dependencies) but
        is built as PIC, then a single instance of that dependency loaded in physical memory may be shared among various processes by mapping that
        instance at any address in the virtual memory address space of those processes. However, if a given dependency contains external symbol
        references and is built in a position dependent form, a single instance of that dependency loaded in physical memory may be shared among
        various processes only if two conditions are met. The first condition is that the memory address range occupied by that instance of the loaded
        dependency is also available in the virtual memory address space of the sharing processes. The second condition is that NO relocation of
        external symbols are allowed to be performed again as to change the current values. In effect, this condition may be hard to satisfy, since it
        would imply that all external symbol definitions with respect to the dependency module need to be available at the same addresses in the
        virtual memory address space of all sharing processes. Another implication of this is that if the above mentioned external symbol definitions
        are provided by sub-dependencies, then the layout of those sub-dependencies in the virtual memory address space of the sharing processes also
        needs to be the same. (All this is not considering the case that the above mentioned external symbol definitions may need to be located in the
        “text” segment of the main program of the various sharing processes.)
      </p>
    </ki-topic>
  </ki-topic>
  <ki-topic id="libraries-static-vs-dynamic" name="Libraries: Static Vs Dynamic">
    <ki-reflist>
      <ki-ref link="https://www.youtube.com/watch?v=or1dAmUO8k0"></ki-ref>
      <ki-ref link="https://www.youtube.com/watch?v=pLy69V2F_8M"></ki-ref>
      <ki-ref link="https://www.youtube.com/watch?v=Wt4dxDNmDA8"></ki-ref>
      <ki-ref link="https://www.cprogramming.com/tutorial/shared-libraries-linux-gcc.html"></ki-ref>
      <ki-ref link="https://www.cyberciti.biz/tips/linux-shared-library-management.html"></ki-ref>
      <ki-ref link="https://tldp.org/HOWTO/Program-Library-HOWTO/index.html"></ki-ref>
      <ki-ref link="http://www.yolinux.com/TUTORIALS/LibraryArchives-StaticAndDynamic.html"></ki-ref>
      <ki-ref link="https://akkadia.org/drepper/dsohowto.pdf"></ki-ref>
    </ki-reflist>
  </ki-topic>
  <ki-topic id="elf-and-pe" name="About ELF and PE">
    <ki-reflist>
      <ki-ref link="http://www.skyfree.org/linux/references/ELF_Format.pdf"></ki-ref>
      <ki-ref link="https://docs.microsoft.com/en-us/windows/win32/debug/pe-format"></ki-ref>
      <ki-ref link="http://blog.k3170makan.com/search?q=elf"></ki-ref>
    </ki-reflist>
  </ki-topic>
  <ki-topic name="Using GNU Compiler Collection (GCC)">
    See resource at <ki-link path="/cpp#gcc"></ki-link>.
  </ki-topic>
  <ki-topic id="about-web-development" name="About Web Development">
    <ki-reflist>
      <ki-ref link="https://www.youtube.com/watch?v=BEoFSRdkSZQ">
        Commentary on the web development learning roadmap for front-end development, back-end development and devOps.
      </ki-ref>
      <ki-ref link="https://github.com/kamranahmedse/developer-roadmap">Graphical images of the web development roadmaps.</ki-ref>
    </ki-reflist>
    <ki-topic id="lamp-stack" name="LAMP Web Development Stack">
      <ki-reflist>
        <ki-ref link="https://www.ibm.com/cloud/learn/lamp-stack-explained">About LAMP.</ki-ref>
        <ki-ref link="https://www.digitalocean.com/community/tutorials/how-to-install-linux-apache-mysql-php-lamp-stack-ubuntu-18-04">
          Setting up and configuring LAMP.
        </ki-ref>
        <ki-ref link="https://www.ibm.com/developerworks/web/tutorials/wa-lamp/wa-lamp.html">Using MySQL and PHP in LAMP environment.</ki-ref>
      </ki-reflist>
      <ki-topic id="apache-web-server" name="Apache Web Server">
        <ki-reflist>
          <ki-ref link="https://www.hostinger.com/tutorials/what-is-apache">About Apache.</ki-ref>
          <ki-ref link="https://www.guru99.com/apache.html">Setting up and configuring Apache.</ki-ref>
          <ki-ref link="https://github.com/apache/httpd">Apache source repository.</ki-ref>
        </ki-reflist>
      </ki-topic>
    </ki-topic>
    <ki-topic id="mean-stack" name="MEAN Web Development Stack">
      <ki-reflist>
        <ki-ref link="https://en.wikipedia.org/wiki/MEAN_(solution_stack)">About MEAN.</ki-ref>
        <ki-ref link="https://en.wikipedia.org/wiki/Express.js">
          About
          <em>Express.js</em>
          .
        </ki-ref>
      </ki-reflist>
    </ki-topic>
  </ki-topic>
  <ki-topic id="about-mobile-app-development" name="About Mobile Application Development">
    <ki-reflist>
      <ki-ref link="https://www.youtube.com/watch?v=ZikVtdopsfY">Introduction to mobile app development.</ki-ref>
      <ki-ref link="https://www.youtube.com/watch?v=Nh0F_okJAkA">
        About the future of the industry with respect to mobile app development. (Dated Feb. 2019)
      </ki-ref>
      <ki-ref link="https://www.youtube.com/watch?v=svGztRj5bvs">About some of the top mobile app development solution stacks.</ki-ref>
      <ki-ref link="https://www.youtube.com/watch?v=4m7msadL5iA">Detailed comparison of various mobile app development solution stacks.</ki-ref>
      <ki-ref link="https://www.youtube.com/watch?v=PKRXbLnfXXk">
        Even more detailed comparison of various mobile app development solution stacks.
      </ki-ref>
      <ki-ref link="https://www.youtube.com/watch?v=PgkZc2s5r5E">
        Comparison of mobile app development versus web development as career path. (Dated Aug. 2019)
      </ki-ref>
    </ki-reflist>
    <ki-topic id="android-development" name="Android Software Development">
      <ki-reflist>
        <ki-ref link="https://en.wikipedia.org/wiki/Android_software_development">About Android software development.</ki-ref>
        <ki-ref link="http://androiddeveloper.galileo.edu/2017/03/08/android-ndk-vs-android-sdk/">
          Comparison of Android NDK versus Android SDK.
        </ki-ref>
        <ki-ref link="https://stackoverflow.com/questions/7839218/android-ndk-vs-sdk-if-features-are-concerned">
          Commentaries about Android NDK versus Android SDK.
        </ki-ref>
      </ki-reflist>
    </ki-topic>
  </ki-topic>
  <ki-topic id="jwt" name="JSON Web Token">
    <ki-reflist>
      <ki-ref link="https://www.youtube.com/watch?v=soGRyl9ztjI">Java Brains - What is JWT authorization really about</ki-ref>
      <ki-ref link="https://www.youtube.com/watch?v=_XbXkVdoG_0">Java Brains - What is the structure of a JWT</ki-ref>
      <ki-ref link="https://www.youtube.com/watch?v=T0k-3Ze4NLo">Hussein Nasser - JWT - JSON Web Token Crash Course (NodeJS &amp; Postgres)</ki-ref>
      <ki-ref link="https://medium.com/devgorilla/how-to-log-out-when-using-jwt-a8c7823e8a6">How to log out when using JWT</ki-ref>
    </ki-reflist>
  </ki-topic>
</ki-section>
